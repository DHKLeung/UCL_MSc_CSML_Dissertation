{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"pytorch breast NN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HjQFMCiIcZe-"},"source":["# Import Libraries"],"id":"HjQFMCiIcZe-"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"proprietary-livestock","executionInfo":{"status":"ok","timestamp":1624929506686,"user_tz":-60,"elapsed":17348,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"c3d44d05-3100-4d2b-92e1-7c9dd8a4e123"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"proprietary-livestock","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3J4pCTXbcd6t"},"source":["# Import outside code"],"id":"3J4pCTXbcd6t"},{"cell_type":"code","metadata":{"id":"JkezIXshcjXk","executionInfo":{"status":"ok","timestamp":1624929507480,"user_tz":-60,"elapsed":796,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"JkezIXshcjXk","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQA_AHCwcjP2","executionInfo":{"status":"ok","timestamp":1624929507819,"user_tz":-60,"elapsed":340,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"xQA_AHCwcjP2","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rUq68SsPcqR-"},"source":["# Configuration"],"id":"rUq68SsPcqR-"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"silent-johns","executionInfo":{"status":"ok","timestamp":1624929507820,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"b58f31fd-7f12-4a40-f2b8-196d9d416cd0"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","batch_size = 128\n","step_size = 0.005\n","random_seed = 0\n","epochs = 300\n","L2_decay = 1e-4\n","\n","torch.manual_seed(random_seed)"],"id":"silent-johns","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fae61a2fa50>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"pwVfl6ficzJH"},"source":["# Data"],"id":"pwVfl6ficzJH"},{"cell_type":"code","metadata":{"id":"compressed-schedule","executionInfo":{"status":"ok","timestamp":1624929507820,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["train_data, train_labels, val_data, val_labels, test_data, test_labels = load_skl_data('breast_cancer')\n","test_data = np.vstack((val_data, test_data))\n","test_labels = np.hstack((val_labels, test_labels))\n","train_data = torch.from_numpy(train_data).type(torch.FloatTensor)\n","train_labels = torch.from_numpy(train_labels)\n","test_data = torch.from_numpy(test_data).type(torch.FloatTensor)\n","test_labels = torch.from_numpy(test_labels)\n","train_mean = torch.mean(train_data, 0)\n","train_std = torch.std(train_data, 0)\n","train_data = (train_data - train_mean) / train_std\n","test_data = (test_data - train_mean) / train_std\n","train_set = torch.utils.data.TensorDataset(train_data, train_labels)\n","test_set = torch.utils.data.TensorDataset(test_data, test_labels)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"compressed-schedule","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L69dJwSHdDtI"},"source":["# Models, Loss, Optimiser"],"id":"L69dJwSHdDtI"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buried-science","executionInfo":{"status":"ok","timestamp":1624929514665,"user_tz":-60,"elapsed":6848,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"5dd5b01e-4979-4265-a46e-b012cf75e5c6"},"source":["class fc_model(nn.Module):\n","    def __init__(self):\n","        super(fc_model, self).__init__()\n","        self.fc1 = nn.Linear(30, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 1)\n","    def forward(self, inputs):\n","        fc1_out = F.tanh(self.fc1(inputs))\n","        fc2_out = F.tanh(self.fc2(fc1_out))\n","        fc3_out = F.tanh(self.fc3(fc2_out))\n","        fc4_out = self.fc4(fc3_out)\n","        return fc4_out\n","\n","model = fc_model()\n","criterion = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"buried-science","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["fc_model(\n","  (fc1): Linear(in_features=30, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=32, bias=True)\n","  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"HwiWYl0ddK3s"},"source":["# Training"],"id":"HwiWYl0ddK3s"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pediatric-namibia","executionInfo":{"status":"ok","timestamp":1624929516831,"user_tz":-60,"elapsed":2170,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"de3d433e-9f70-4378-98f2-f0face9ff40a"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","\n","        # Original, calculate loss #\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Record #\n","        epoch_loss += loss.item()\n","\n","        # Gradient Calculation & Optimisation #\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print loss #\n","    print('{}: {}'.format(epoch, epoch_loss))"],"id":"pediatric-namibia","execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["0: 2.1258270144462585\n","1: 2.090251863002777\n","2: 2.0396276116371155\n","3: 1.973351001739502\n","4: 1.8980940580368042\n","5: 1.8161482214927673\n","6: 1.7220138311386108\n","7: 1.6315662860870361\n","8: 1.5313378870487213\n","9: 1.4247623980045319\n","10: 1.3221703171730042\n","11: 1.2025853991508484\n","12: 1.1097092628479004\n","13: 1.0035611689090729\n","14: 0.9116801023483276\n","15: 0.8403848111629486\n","16: 0.742875337600708\n","17: 0.6833858042955399\n","18: 0.6227448135614395\n","19: 0.5844448506832123\n","20: 0.5450535267591476\n","21: 0.513314425945282\n","22: 0.4792928546667099\n","23: 0.4562644511461258\n","24: 0.44567975401878357\n","25: 0.4081801474094391\n","26: 0.40959668159484863\n","27: 0.3977350890636444\n","28: 0.3628039062023163\n","29: 0.3648603707551956\n","30: 0.3432907536625862\n","31: 0.3463868275284767\n","32: 0.3363366201519966\n","33: 0.3378380537033081\n","34: 0.3148569315671921\n","35: 0.3099534884095192\n","36: 0.32163509726524353\n","37: 0.3111303001642227\n","38: 0.2844598852097988\n","39: 0.2894848436117172\n","40: 0.2968961372971535\n","41: 0.28185251355171204\n","42: 0.27217715233564377\n","43: 0.27138756215572357\n","44: 0.30201105028390884\n","45: 0.2658174932003021\n","46: 0.26008259877562523\n","47: 0.2481772918254137\n","48: 0.2512521259486675\n","49: 0.2604011446237564\n","50: 0.25659915804862976\n","51: 0.2802821397781372\n","52: 0.2550394833087921\n","53: 0.2618553191423416\n","54: 0.2689218446612358\n","55: 0.2502707839012146\n","56: 0.2420971915125847\n","57: 0.24173234030604362\n","58: 0.2632986977696419\n","59: 0.26269685477018356\n","60: 0.24389678984880447\n","61: 0.25244440138339996\n","62: 0.23831752687692642\n","63: 0.24568718671798706\n","64: 0.25599629431962967\n","65: 0.23230654746294022\n","66: 0.2493121139705181\n","67: 0.22191805019974709\n","68: 0.2573804594576359\n","69: 0.22881129011511803\n","70: 0.248684611171484\n","71: 0.24434655159711838\n","72: 0.22977297753095627\n","73: 0.22130289301276207\n","74: 0.23440377414226532\n","75: 0.25522150844335556\n","76: 0.22613339498639107\n","77: 0.23670580238103867\n","78: 0.23352284729480743\n","79: 0.22868139296770096\n","80: 0.22266840934753418\n","81: 0.24245820194482803\n","82: 0.22151069343090057\n","83: 0.2211155742406845\n","84: 0.220649566501379\n","85: 0.24159954115748405\n","86: 0.21683703735470772\n","87: 0.23743287473917007\n","88: 0.2190580666065216\n","89: 0.2110218182206154\n","90: 0.2171688675880432\n","91: 0.22053640335798264\n","92: 0.20033473894000053\n","93: 0.20240982621908188\n","94: 0.2300645038485527\n","95: 0.20065707340836525\n","96: 0.20923666656017303\n","97: 0.20049655064940453\n","98: 0.22541182860732079\n","99: 0.21467653661966324\n","100: 0.21220675855875015\n","101: 0.20678498968482018\n","102: 0.22033900395035744\n","103: 0.2117345631122589\n","104: 0.1924891099333763\n","105: 0.2152206003665924\n","106: 0.20929212123155594\n","107: 0.19476735591888428\n","108: 0.1896188072860241\n","109: 0.2012840323150158\n","110: 0.18346675671637058\n","111: 0.19187845289707184\n","112: 0.1882098764181137\n","113: 0.1858722995966673\n","114: 0.18575578555464745\n","115: 0.19077645987272263\n","116: 0.195078257471323\n","117: 0.20964929834008217\n","118: 0.21308146230876446\n","119: 0.19808929413557053\n","120: 0.20406565070152283\n","121: 0.20600392669439316\n","122: 0.17875147983431816\n","123: 0.1832558773458004\n","124: 0.21683715283870697\n","125: 0.17590457759797573\n","126: 0.19805556535720825\n","127: 0.1797228343784809\n","128: 0.17895640060305595\n","129: 0.18010736256837845\n","130: 0.20284637808799744\n","131: 0.18839368224143982\n","132: 0.18217334151268005\n","133: 0.17593486607074738\n","134: 0.2050043884664774\n","135: 0.17414163798093796\n","136: 0.195732980966568\n","137: 0.18721803650259972\n","138: 0.18661769479513168\n","139: 0.18506725132465363\n","140: 0.19955235719680786\n","141: 0.1756240725517273\n","142: 0.1808103546500206\n","143: 0.1787864863872528\n","144: 0.18290643393993378\n","145: 0.17998561635613441\n","146: 0.17494865506887436\n","147: 0.17012890055775642\n","148: 0.18015608936548233\n","149: 0.17418063804507256\n","150: 0.16580806858837605\n","151: 0.19037837907671928\n","152: 0.2036593295633793\n","153: 0.18248075246810913\n","154: 0.16998108848929405\n","155: 0.16730943508446217\n","156: 0.1840229518711567\n","157: 0.17410851269960403\n","158: 0.17007606104016304\n","159: 0.18351218290627003\n","160: 0.18147312849760056\n","161: 0.17466923594474792\n","162: 0.1638739723712206\n","163: 0.16768969595432281\n","164: 0.1814165599644184\n","165: 0.1739628128707409\n","166: 0.16663031838834286\n","167: 0.1826227605342865\n","168: 0.1657550036907196\n","169: 0.16233036667108536\n","170: 0.16749367117881775\n","171: 0.18248790875077248\n","172: 0.163757449015975\n","173: 0.18304017931222916\n","174: 0.17349388264119625\n","175: 0.18114073574543\n","176: 0.18713752552866936\n","177: 0.17958607152104378\n","178: 0.17444954067468643\n","179: 0.18585899099707603\n","180: 0.1698007583618164\n","181: 0.1952608861029148\n","182: 0.16626128368079662\n","183: 0.1739940233528614\n","184: 0.1616329587996006\n","185: 0.1829642504453659\n","186: 0.17947913333773613\n","187: 0.16077209822833538\n","188: 0.16814416274428368\n","189: 0.19657309725880623\n","190: 0.16849521175026894\n","191: 0.17451023682951927\n","192: 0.16464529000222683\n","193: 0.177321657538414\n","194: 0.1717020757496357\n","195: 0.1846916638314724\n","196: 0.1697493940591812\n","197: 0.1601801896467805\n","198: 0.16833719611167908\n","199: 0.1643982008099556\n","200: 0.1644370947033167\n","201: 0.17779935523867607\n","202: 0.17497457563877106\n","203: 0.17893929407000542\n","204: 0.16050203330814838\n","205: 0.17226485535502434\n","206: 0.18078577145934105\n","207: 0.17000122740864754\n","208: 0.17661086469888687\n","209: 0.17681315913796425\n","210: 0.16142536886036396\n","211: 0.18292193859815598\n","212: 0.16795597597956657\n","213: 0.1610522512346506\n","214: 0.15982847474515438\n","215: 0.1678977608680725\n","216: 0.17543994262814522\n","217: 0.16404676251113415\n","218: 0.17042475566267967\n","219: 0.18768098205327988\n","220: 0.17159534245729446\n","221: 0.18509863317012787\n","222: 0.1944009605795145\n","223: 0.1631985753774643\n","224: 0.18114635720849037\n","225: 0.16441330686211586\n","226: 0.17027708515524864\n","227: 0.17710231617093086\n","228: 0.16170631535351276\n","229: 0.17761795595288277\n","230: 0.17017335072159767\n","231: 0.16368580609560013\n","232: 0.17053169943392277\n","233: 0.1783692128956318\n","234: 0.17729338631033897\n","235: 0.16457652673125267\n","236: 0.1684907265007496\n","237: 0.18292100355029106\n","238: 0.16503935307264328\n","239: 0.18384477123618126\n","240: 0.17568787932395935\n","241: 0.17174583673477173\n","242: 0.1767367608845234\n","243: 0.16988533735275269\n","244: 0.1773560382425785\n","245: 0.17054598778486252\n","246: 0.17536302283406258\n","247: 0.1727574449032545\n","248: 0.17167558521032333\n","249: 0.1748078055679798\n","250: 0.1645132228732109\n","251: 0.1696108691394329\n","252: 0.1634312216192484\n","253: 0.17267699539661407\n","254: 0.17060522735118866\n","255: 0.17199687287211418\n","256: 0.18349837139248848\n","257: 0.17196116968989372\n","258: 0.1662726141512394\n","259: 0.16185075975954533\n","260: 0.17087668552994728\n","261: 0.16453947126865387\n","262: 0.1632186621427536\n","263: 0.18036122247576714\n","264: 0.17559342458844185\n","265: 0.166269201785326\n","266: 0.1836959570646286\n","267: 0.1802610233426094\n","268: 0.18708928301930428\n","269: 0.16003922559320927\n","270: 0.18804173357784748\n","271: 0.18074642680585384\n","272: 0.18380065634846687\n","273: 0.18604286760091782\n","274: 0.16639969870448112\n","275: 0.160312682390213\n","276: 0.18236993253231049\n","277: 0.15967771410942078\n","278: 0.16682082414627075\n","279: 0.20083997026085854\n","280: 0.17112154886126518\n","281: 0.16447080299258232\n","282: 0.1599794514477253\n","283: 0.19342667423188686\n","284: 0.17088865488767624\n","285: 0.18292609229683876\n","286: 0.16876666620373726\n","287: 0.1716591641306877\n","288: 0.15971647016704082\n","289: 0.17198169603943825\n","290: 0.16282636299729347\n","291: 0.16054332628846169\n","292: 0.1617765761911869\n","293: 0.1644052490592003\n","294: 0.16116750985383987\n","295: 0.16406888887286186\n","296: 0.1563926748931408\n","297: 0.1810719333589077\n","298: 0.16064931266009808\n","299: 0.17172953113913536\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sKltRaTad3bv"},"source":["# Save model"],"id":"sKltRaTad3bv"},{"cell_type":"code","metadata":{"id":"brief-details","executionInfo":{"status":"ok","timestamp":1624929516831,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["# torch.save(model.state_dict(), './model_pytorch_breast')\n","# model = fc_model()\n","# model.load_state_dict(torch.load('./model_pytorch_breast'))"],"id":"brief-details","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yWMRLkjid54k"},"source":["# Test on Test Data"],"id":"yWMRLkjid54k"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latin-interest","executionInfo":{"status":"ok","timestamp":1624929516832,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"8e0ea9a6-be68-4cc9-8136-a7b8df1f86dc"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","        outputs = model(inputs)\n","        predicts = (torch.sign(outputs) + 1) / 2\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"latin-interest","execution_count":9,"outputs":[{"output_type":"stream","text":["0.9736842105263158\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"aLFb2OCed7uU"},"source":["# Test on Train Data"],"id":"aLFb2OCed7uU"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resident-overall","executionInfo":{"status":"ok","timestamp":1624929516832,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"fddfa90d-0168-41a5-b218-f7daa1f6eebf"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","        outputs = model(inputs)\n","        predicts = (torch.sign(outputs) + 1) / 2\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"resident-overall","execution_count":10,"outputs":[{"output_type":"stream","text":["0.9853372434017595\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"preceding-galaxy","executionInfo":{"status":"ok","timestamp":1624929516832,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":[""],"id":"preceding-galaxy","execution_count":10,"outputs":[]}]}