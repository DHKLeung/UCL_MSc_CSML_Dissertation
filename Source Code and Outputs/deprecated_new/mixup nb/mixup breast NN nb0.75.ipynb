{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"mixup breast NN nb0.75.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NyrKck5mLTzj"},"source":["# Import Libraries"],"id":"NyrKck5mLTzj"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"proprietary-livestock","executionInfo":{"status":"ok","timestamp":1625253555178,"user_tz":-60,"elapsed":563,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"592299fd-dc9b-48c5-e7a2-b80263f78aaf"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"proprietary-livestock","execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GFBzaRxYLmIz"},"source":["# Import outside code"],"id":"GFBzaRxYLmIz"},{"cell_type":"code","metadata":{"id":"mSeLSa5KLn_5"},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"mSeLSa5KLn_5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KU2jvzwwLn5W"},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"KU2jvzwwLn5W","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o5PtGmQoLrl7"},"source":["# Configuration"],"id":"o5PtGmQoLrl7"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"silent-johns","executionInfo":{"status":"ok","timestamp":1625253555942,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"ed65e2ab-47dc-4ef6-eb1e-1e36eca7c7ba"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","batch_size = 128\n","step_size = 0.005\n","random_seed = 0\n","epochs = 300\n","L2_decay = 1e-4\n","alpha = 1.\n","geometric_param = 0.75\n","\n","torch.manual_seed(random_seed)"],"id":"silent-johns","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f3d4684eb90>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"NRldvRO1L28r"},"source":["# Data"],"id":"NRldvRO1L28r"},{"cell_type":"code","metadata":{"id":"compressed-schedule"},"source":["train_data, train_labels, val_data, val_labels, test_data, test_labels = load_skl_data('breast_cancer')\n","test_data = np.vstack((val_data, test_data))\n","test_labels = np.hstack((val_labels, test_labels))\n","train_data = torch.from_numpy(train_data).type(torch.FloatTensor)\n","train_labels = torch.from_numpy(train_labels)\n","test_data = torch.from_numpy(test_data).type(torch.FloatTensor)\n","test_labels = torch.from_numpy(test_labels)\n","train_mean = torch.mean(train_data, 0)\n","train_std = torch.std(train_data, 0)\n","train_data = (train_data - train_mean) / train_std\n","test_data = (test_data - train_mean) / train_std\n","train_set = torch.utils.data.TensorDataset(train_data, train_labels)\n","test_set = torch.utils.data.TensorDataset(test_data, test_labels)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"compressed-schedule","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6loof5Y_L6ry"},"source":["# Model, Loss, Optimiser"],"id":"6loof5Y_L6ry"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buried-science","executionInfo":{"status":"ok","timestamp":1625253558530,"user_tz":-60,"elapsed":2591,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"e520858e-9727-4f95-e23b-2041c0cdd1ba"},"source":["class fc_model(nn.Module):\n","    def __init__(self):\n","        super(fc_model, self).__init__()\n","        self.fc1 = nn.Linear(30, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 1)\n","    def forward(self, inputs):\n","        fc1_out = F.tanh(self.fc1(inputs))\n","        fc2_out = F.tanh(self.fc2(fc1_out))\n","        fc3_out = F.tanh(self.fc3(fc2_out))\n","        fc4_out = self.fc4(fc3_out)\n","        return fc4_out\n","\n","model = fc_model()\n","criterion = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"buried-science","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["fc_model(\n","  (fc1): Linear(in_features=30, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=32, bias=True)\n","  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"kaMBwZHaMIRn"},"source":["# Data Augmentation / Perturbation AND corresponding loss"],"id":"kaMBwZHaMIRn"},{"cell_type":"code","metadata":{"id":"quiet-module"},"source":["def mixup_breast_nb(inputs, labels, geometric_param, alpha):\n","    inner_batch_size = labels.size(0)\n","    inputs_flatten = inputs.reshape(inner_batch_size, -1)\n","\n","    # Compute pair-wise distances & sort the distances #\n","    dists = torch.cdist(inputs_flatten, inputs_flatten)\n","    sort_idx = torch.argsort(dists, dim=1)\n","    sort_idx_no_itself = sort_idx[:, 1:]\n","\n","    # Generate geometric random variables for selecting neighbours & get the index of selected neighbour data #\n","    select_idx = torch.distributions.geometric.Geometric(geometric_param).sample_n(inner_batch_size).type(torch.LongTensor).to('cuda')\n","    select_idx_clipped = torch.clamp(select_idx, max=inner_batch_size - 2)\n","    nb_idx = sort_idx_no_itself[torch.arange(inner_batch_size), select_idx_clipped]\n","\n","    # mixup with neighbours #\n","    inputs_nb = inputs[nb_idx]\n","    labels_nb = labels[nb_idx]\n","    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample().to('cuda')\n","    mixup_inputs_nb = lmbda * inputs + (1 - lmbda) * inputs_nb\n","    return mixup_inputs_nb, labels, labels_nb, lmbda"],"id":"quiet-module","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"opening-sessions"},"source":["def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n","    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n","    return mixup_loss"],"id":"opening-sessions","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQOqDOmDMYOj"},"source":["# Training"],"id":"SQOqDOmDMYOj"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pediatric-namibia","executionInfo":{"status":"ok","timestamp":1625253561412,"user_tz":-60,"elapsed":2884,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"3a2b55e4-5aeb-4ac7-9efc-7145199ed5fb"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","\n","        # Mixup with random neighbour #\n","        mixup_inputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda = mixup_breast_nb(inputs, labels, geometric_param, alpha)\n","        mixup_outputs_nb = model(mixup_inputs_nb)\n","        mixup_loss_nb = mixup_criterion(criterion, mixup_outputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda)\n","\n","        # Record #\n","        epoch_loss += mixup_loss_nb.item()\n","\n","        # Gradient Calculation & Optimisation #\n","        mixup_loss_nb.backward()\n","        optimizer.step()\n","    \n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print loss #\n","    print('{}: {}'.format(epoch, epoch_loss))"],"id":"pediatric-namibia","execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:151: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n","  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["0: 2.1264330744743347\n","1: 2.0931935906410217\n","2: 2.038053870201111\n","3: 1.9668885469436646\n","4: 1.88007253408432\n","5: 1.7827879786491394\n","6: 1.696803867816925\n","7: 1.5878962278366089\n","8: 1.4847773909568787\n","9: 1.3660228848457336\n","10: 1.2441638112068176\n","11: 1.138515293598175\n","12: 1.0351002514362335\n","13: 0.9032357931137085\n","14: 0.8317439258098602\n","15: 0.7813624441623688\n","16: 0.7104258686304092\n","17: 0.6695630550384521\n","18: 0.6001792103052139\n","19: 0.5453922599554062\n","20: 0.5483207553625107\n","21: 0.5296740233898163\n","22: 0.4933267831802368\n","23: 0.4924312010407448\n","24: 0.4587375223636627\n","25: 0.44202516973018646\n","26: 0.4224570095539093\n","27: 0.4249318987131119\n","28: 0.3999553918838501\n","29: 0.38296596705913544\n","30: 0.404839426279068\n","31: 0.3386183828115463\n","32: 0.44221168011426926\n","33: 0.36625927686691284\n","34: 0.35579483211040497\n","35: 0.35234368592500687\n","36: 0.3569996654987335\n","37: 0.2563503384590149\n","38: 0.3455468639731407\n","39: 0.38957805931568146\n","40: 0.39520661532878876\n","41: 0.3058488592505455\n","42: 0.3224412649869919\n","43: 0.36503608524799347\n","44: 0.3754350244998932\n","45: 0.33765267580747604\n","46: 0.34438933432102203\n","47: 0.31079471856355667\n","48: 0.34356561303138733\n","49: 0.3590254485607147\n","50: 0.34563135355710983\n","51: 0.3356955796480179\n","52: 0.33292750269174576\n","53: 0.319391205906868\n","54: 0.28312812745571136\n","55: 0.3335103690624237\n","56: 0.35403773188591003\n","57: 0.3707902505993843\n","58: 0.2741502784192562\n","59: 0.4043615609407425\n","60: 0.33012060075998306\n","61: 0.337112657725811\n","62: 0.2421625778079033\n","63: 0.3092629685997963\n","64: 0.3152119778096676\n","65: 0.32096579670906067\n","66: 0.3277650624513626\n","67: 0.3437951058149338\n","68: 0.418780580163002\n","69: 0.3111480697989464\n","70: 0.2979976162314415\n","71: 0.32777123153209686\n","72: 0.3084563761949539\n","73: 0.2768503688275814\n","74: 0.35080358386039734\n","75: 0.28963951393961906\n","76: 0.3506859466433525\n","77: 0.31634706258773804\n","78: 0.29413603246212006\n","79: 0.32395604997873306\n","80: 0.28341346234083176\n","81: 0.2988325133919716\n","82: 0.31310277432203293\n","83: 0.2662212699651718\n","84: 0.2886520251631737\n","85: 0.26281170547008514\n","86: 0.31304000690579414\n","87: 0.31303441524505615\n","88: 0.2823049873113632\n","89: 0.36790014803409576\n","90: 0.30576980113983154\n","91: 0.34028370678424835\n","92: 0.36698368191719055\n","93: 0.3404133766889572\n","94: 0.2588939592242241\n","95: 0.2913627028465271\n","96: 0.2974911853671074\n","97: 0.2954188287258148\n","98: 0.3127720504999161\n","99: 0.3700558543205261\n","100: 0.2912709563970566\n","101: 0.3141041025519371\n","102: 0.26771100610494614\n","103: 0.3555668294429779\n","104: 0.2850377783179283\n","105: 0.3181431107223034\n","106: 0.2653380483388901\n","107: 0.3649269938468933\n","108: 0.2824554778635502\n","109: 0.3210717588663101\n","110: 0.21206297725439072\n","111: 0.29994627088308334\n","112: 0.27628566324710846\n","113: 0.316371813416481\n","114: 0.3163795694708824\n","115: 0.29938194900751114\n","116: 0.37005744501948357\n","117: 0.2805735692381859\n","118: 0.3608686700463295\n","119: 0.352544330060482\n","120: 0.20257844775915146\n","121: 0.21801405400037766\n","122: 0.26129423826932907\n","123: 0.32272250205278397\n","124: 0.385747242718935\n","125: 0.30509382486343384\n","126: 0.2327670231461525\n","127: 0.2927500456571579\n","128: 0.2952098101377487\n","129: 0.3015366718173027\n","130: 0.3026545122265816\n","131: 0.35191166400909424\n","132: 0.3816417530179024\n","133: 0.33206528425216675\n","134: 0.30109791457653046\n","135: 0.35577278584241867\n","136: 0.2918953374028206\n","137: 0.32694709300994873\n","138: 0.2931806668639183\n","139: 0.3456700798124075\n","140: 0.31883544474840164\n","141: 0.2756003253161907\n","142: 0.29350876063108444\n","143: 0.23267604783177376\n","144: 0.23184436559677124\n","145: 0.24272139370441437\n","146: 0.289389431476593\n","147: 0.31564175337553024\n","148: 0.2606279142200947\n","149: 0.3144111931324005\n","150: 0.3227106183767319\n","151: 0.3481762632727623\n","152: 0.3279159292578697\n","153: 0.2974116653203964\n","154: 0.28673210740089417\n","155: 0.35100189596414566\n","156: 0.3639441058039665\n","157: 0.30273834988474846\n","158: 0.23129452019929886\n","159: 0.3231334239244461\n","160: 0.28332433104515076\n","161: 0.28728536516427994\n","162: 0.2945231758058071\n","163: 0.3944801688194275\n","164: 0.30094777792692184\n","165: 0.2813991717994213\n","166: 0.2843567207455635\n","167: 0.3094050046056509\n","168: 0.32183703780174255\n","169: 0.37103019654750824\n","170: 0.2757292613387108\n","171: 0.2828124165534973\n","172: 0.3191918469965458\n","173: 0.26245054975152016\n","174: 0.271330364048481\n","175: 0.3092532902956009\n","176: 0.2654952108860016\n","177: 0.28216347843408585\n","178: 0.3555753603577614\n","179: 0.32902318239212036\n","180: 0.2407507747411728\n","181: 0.31038210541009903\n","182: 0.3485982194542885\n","183: 0.31035663560032845\n","184: 0.27823933213949203\n","185: 0.3230450972914696\n","186: 0.30841483920812607\n","187: 0.2960776388645172\n","188: 0.26680465415120125\n","189: 0.274726003408432\n","190: 0.3887317478656769\n","191: 0.25989460200071335\n","192: 0.3016652539372444\n","193: 0.37294668704271317\n","194: 0.34915638715028763\n","195: 0.2837541401386261\n","196: 0.2850615680217743\n","197: 0.2895337641239166\n","198: 0.29886317625641823\n","199: 0.32866794988512993\n","200: 0.275383785367012\n","201: 0.26989932730793953\n","202: 0.3091556280851364\n","203: 0.3225967139005661\n","204: 0.3240503706037998\n","205: 0.37116966024041176\n","206: 0.2286740019917488\n","207: 0.25836973637342453\n","208: 0.36642638593912125\n","209: 0.2645414024591446\n","210: 0.28181979432702065\n","211: 0.2717256024479866\n","212: 0.34530192613601685\n","213: 0.21434292942285538\n","214: 0.3117843493819237\n","215: 0.23303544521331787\n","216: 0.2812710851430893\n","217: 0.24856816232204437\n","218: 0.27433924190700054\n","219: 0.23014259338378906\n","220: 0.2771205045282841\n","221: 0.2988335192203522\n","222: 0.27017420530319214\n","223: 0.2803867422044277\n","224: 0.3466384559869766\n","225: 0.29137828201055527\n","226: 0.30094704777002335\n","227: 0.3139299005270004\n","228: 0.3003840819001198\n","229: 0.28984295576810837\n","230: 0.3586370572447777\n","231: 0.2777230404317379\n","232: 0.24775657802820206\n","233: 0.27769047766923904\n","234: 0.25048957020044327\n","235: 0.21687599271535873\n","236: 0.24169626459479332\n","237: 0.29657942056655884\n","238: 0.2937866672873497\n","239: 0.3022664487361908\n","240: 0.3399607688188553\n","241: 0.22943780943751335\n","242: 0.30969419330358505\n","243: 0.2789272740483284\n","244: 0.2706936113536358\n","245: 0.2720758132636547\n","246: 0.2431577928364277\n","247: 0.3316385895013809\n","248: 0.3122457265853882\n","249: 0.2783174440264702\n","250: 0.3037494570016861\n","251: 0.2692122086882591\n","252: 0.26589588075876236\n","253: 0.2477397546172142\n","254: 0.3431815207004547\n","255: 0.3056763932108879\n","256: 0.32293789088726044\n","257: 0.2786281257867813\n","258: 0.33178040385246277\n","259: 0.25433872640132904\n","260: 0.30446162819862366\n","261: 0.2909456342458725\n","262: 0.4010782465338707\n","263: 0.33211998641490936\n","264: 0.27435706555843353\n","265: 0.24959922581911087\n","266: 0.3363804668188095\n","267: 0.2667549066245556\n","268: 0.29835207015275955\n","269: 0.3223235756158829\n","270: 0.34567292034626007\n","271: 0.33060819655656815\n","272: 0.24488741904497147\n","273: 0.2773462198674679\n","274: 0.33043482154607773\n","275: 0.3183097094297409\n","276: 0.29601357132196426\n","277: 0.2684706002473831\n","278: 0.25128666311502457\n","279: 0.23607441782951355\n","280: 0.2793820984661579\n","281: 0.24589622020721436\n","282: 0.31044951826334\n","283: 0.28435683995485306\n","284: 0.34480567276477814\n","285: 0.32981838285923004\n","286: 0.314215250313282\n","287: 0.2014477327466011\n","288: 0.29619763419032097\n","289: 0.2924879118800163\n","290: 0.3697276711463928\n","291: 0.3271790184080601\n","292: 0.3402145951986313\n","293: 0.2789594903588295\n","294: 0.31066131591796875\n","295: 0.2681503891944885\n","296: 0.33436451107263565\n","297: 0.34979987144470215\n","298: 0.3045819289982319\n","299: 0.2853601723909378\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CL1h58tJNu56"},"source":["# Save model"],"id":"CL1h58tJNu56"},{"cell_type":"code","metadata":{"id":"brief-details"},"source":["# torch.save(model.state_dict(), './mixup_model_pytorch_breast')\n","# model = fc_model()\n","# model.load_state_dict(torch.load('./mixup_model_pytorch_breast'))"],"id":"brief-details","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DydYzZprNxjA"},"source":["# Test on Test Data"],"id":"DydYzZprNxjA"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latin-interest","executionInfo":{"status":"ok","timestamp":1625253561413,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"93c91a8a-2e13-4fa5-eb70-167dddc9f61f"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","        outputs = model(inputs)\n","        predicts = (torch.sign(outputs) + 1) / 2\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"latin-interest","execution_count":null,"outputs":[{"output_type":"stream","text":["0.9824561403508771\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"YLVUq0LdNzfq"},"source":["# Test on Train Data"],"id":"YLVUq0LdNzfq"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resident-overall","executionInfo":{"status":"ok","timestamp":1625253561413,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"d4b5e435-2f3c-4e69-cfa4-7536e8c6ac5b"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","        outputs = model(inputs)\n","        predicts = (torch.sign(outputs) + 1) / 2\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"resident-overall","execution_count":null,"outputs":[{"output_type":"stream","text":["0.9794721407624634\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"preceding-galaxy"},"source":[""],"id":"preceding-galaxy","execution_count":null,"outputs":[]}]}