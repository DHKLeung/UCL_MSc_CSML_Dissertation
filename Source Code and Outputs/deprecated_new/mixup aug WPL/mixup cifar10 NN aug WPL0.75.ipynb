{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"mixup cifar10 NN aug WPL0.75.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_b2Nvqg3Oifz"},"source":["# Import Libraries"],"id":"_b2Nvqg3Oifz"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"romantic-purchase","executionInfo":{"status":"ok","timestamp":1624993373494,"user_tz":-60,"elapsed":23400,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"25edd636-d415-4f34-929d-6f43a3c31f5a"},"source":["import torch\n","from torchvision import transforms, datasets\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"romantic-purchase","execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qiPvZSTKO0Pk"},"source":["# Import outside code"],"id":"qiPvZSTKO0Pk"},{"cell_type":"code","metadata":{"id":"kw0NscKvO2bI"},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"kw0NscKvO2bI","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMYYosNOO2V3"},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"sMYYosNOO2V3","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pg95DAmvO8un"},"source":["# Configuration"],"id":"pg95DAmvO8un"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"silver-clear","executionInfo":{"status":"ok","timestamp":1624993374745,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"3d41652f-b0a9-4c2c-81b9-d6d7e7ff920e"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),  # can omit\n","    transforms.RandomHorizontalFlip(),  # can omit\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        (0.4914, 0.4822, 0.4465),\n","        (0.2023, 0.1994, 0.2010)\n","    )\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        (0.4914, 0.4822, 0.4465),\n","        (0.2023, 0.1994, 0.2010)\n","    )\n","])\n","\n","batch_size = 128\n","step_size = 0.1\n","random_seed = 0\n","epochs = 200\n","L2_decay = 1e-4\n","alpha = 1.\n","perturb_loss_weight = 0.75\n","\n","torch.manual_seed(random_seed)"],"id":"silver-clear","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fba731358d0>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"uDMInb7zPT3v"},"source":["# Data"],"id":"uDMInb7zPT3v"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"relative-mobility","executionInfo":{"status":"ok","timestamp":1624993389281,"user_tz":-60,"elapsed":14538,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"01a32cb8-8b74-4591-e2a3-baaf0cab8c42"},"source":["\"\"\"\n","Data\n","\"\"\"\n","train_set = datasets.CIFAR10(root='/content/gdrive/My Drive/colab', train=True, download=True, transform=transform_train)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_set = datasets.CIFAR10(root='/content/gdrive/My Drive/colab', train=False, download=True, transform=transform_test)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"relative-mobility","execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0-R2uhkAPjkv"},"source":["# Models, Loss, Optimiser"],"id":"0-R2uhkAPjkv"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"starting-chancellor","executionInfo":{"status":"ok","timestamp":1624993395651,"user_tz":-60,"elapsed":6374,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"52f3029a-bcd6-42a5-8868-c51ac40346b5"},"source":["model = ResNet18()\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"starting-chancellor","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layer1): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (linear): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"1qFqkwNmQgeO"},"source":["# Data Augmentation / Perturbation AND corresponding loss"],"id":"1qFqkwNmQgeO"},{"cell_type":"code","metadata":{"id":"contemporary-gross"},"source":["def mixup_cifar10(inputs, labels, alpha):\n","    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample().to('cuda')\n","    batch_size = labels.size(0)\n","    idx = torch.randperm(batch_size).to('cuda')\n","    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n","    labels_b = labels[idx]\n","    return mixup_inputs, labels, labels_b, lmbda"],"id":"contemporary-gross","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"right-spending"},"source":["def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n","    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n","    return mixup_loss"],"id":"right-spending","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlGDo8vIQoZk"},"source":["# Training"],"id":"TlGDo8vIQoZk"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"written-bookmark","executionInfo":{"status":"ok","timestamp":1625003239493,"user_tz":-60,"elapsed":9843849,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"fe10296a-68a1-4560-991f-a6ae57adb9dc"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_mixup_loss = 0.\n","    epoch_loss = 0.\n","    epoch_augment_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","\n","        # Mixup perturbation #\n","        mixup_inputs, mixup_labels_a, mixup_labels_b, lmbda = mixup_cifar10(inputs, labels, alpha)\n","\n","        # Concatenate perturbation and original data, to do augmentation and loss computation #\n","        original_num = inputs.size(0)\n","        augment_inputs = torch.vstack((inputs, mixup_inputs))\n","        augment_outputs = model(augment_inputs)\n","        outputs = augment_outputs[:original_num]\n","        mixup_outputs = augment_outputs[original_num:]\n","        mixup_loss = mixup_criterion(criterion, mixup_outputs, mixup_labels_a, mixup_labels_b, lmbda)\n","        loss = criterion(outputs, labels)\n","        weighted_augment_loss = perturb_loss_weight * mixup_loss + (1 - perturb_loss_weight) * loss\n","\n","        # Record #\n","        epoch_mixup_loss += mixup_loss.item()\n","        epoch_loss += loss.item()\n","        epoch_augment_loss += (mixup_loss.item() + loss.item())\n","\n","        # Gradient Calculation & Optimisation #\n","        weighted_augment_loss.backward()\n","        optimizer.step()\n","    \n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print loss #\n","    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_loss, epoch_augment_loss))"],"id":"written-bookmark","execution_count":null,"outputs":[{"output_type":"stream","text":["0: 754.2879700660706 642.3944388628006 1396.6824089288712\n","1: 640.7222985625267 449.61049181222916 1090.3327903747559\n","2: 587.7168747782707 346.651993393898 934.3688681721687\n","3: 551.9318697452545 282.3850655257702 834.3169352710247\n","4: 532.588649392128 242.6635079085827 775.2521573007107\n","5: 510.7521087229252 213.67232427001 724.4244329929352\n","6: 488.7944229245186 192.79661884903908 681.5910417735577\n","7: 489.0131809413433 173.96167984604836 662.9748607873917\n","8: 469.7195591330528 160.19525888562202 629.9148180186749\n","9: 455.18446692824364 149.01588848233223 604.2003554105759\n","10: 465.1365216970444 136.88937345147133 602.0258951485157\n","11: 464.5674239099026 128.37108597159386 592.9385098814964\n","12: 448.2690674364567 120.1971320360899 568.4661994725466\n","13: 434.9001024365425 114.59070235490799 549.4908047914505\n","14: 447.38713029026985 109.091811850667 556.4789421409369\n","15: 435.68568989634514 102.45327053964138 538.1389604359865\n","16: 446.31816448271275 96.13892725110054 542.4570917338133\n","17: 411.50721649825573 94.15375866740942 505.66097516566515\n","18: 427.89884869754314 89.64373537898064 517.5425840765238\n","19: 421.331861063838 85.89119400829077 507.2230550721288\n","20: 419.51519356667995 83.12007001787424 502.6352635845542\n","21: 420.28756833076477 80.35862009227276 500.64618842303753\n","22: 419.3283960670233 78.67020314186811 497.9985992088914\n","23: 413.63033387064934 78.21974304318428 491.8500769138336\n","24: 421.29238200187683 74.60088005661964 495.8932620584965\n","25: 402.4970068484545 72.13233140856028 474.62933825701475\n","26: 416.22731190919876 69.39448676258326 485.621798671782\n","27: 402.05790105462074 68.84186691045761 470.89976796507835\n","28: 399.59356485307217 66.31188243255019 465.90544728562236\n","29: 414.50041458010674 63.763443034142256 478.263857614249\n","30: 409.4112884029746 62.94955828785896 472.36084669083357\n","31: 404.64315712451935 61.67451645806432 466.31767358258367\n","32: 390.1174291074276 61.8926622569561 452.0100913643837\n","33: 394.3664448708296 60.11122318729758 454.47766805812716\n","34: 409.2729363888502 56.700819831341505 465.9737562201917\n","35: 395.7197178155184 58.19597823172808 453.91569604724646\n","36: 404.4291136711836 55.41254473105073 459.8416584022343\n","37: 392.1027818918228 54.80565996468067 446.9084418565035\n","38: 397.9769866093993 54.776848658919334 452.75383526831865\n","39: 387.9185327142477 54.3814834728837 442.3000161871314\n","40: 381.64556324481964 54.872423090040684 436.5179863348603\n","41: 395.28315076977015 54.09596570581198 449.3791164755821\n","42: 392.66947250813246 51.28120301477611 443.95067552290857\n","43: 390.9732846915722 50.701686173677444 441.67497086524963\n","44: 402.62180333584547 49.682626865804195 452.30443020164967\n","45: 393.2354141846299 50.21765273436904 443.45306691899896\n","46: 383.6145530939102 50.850079990923405 434.4646330848336\n","47: 382.3977076485753 49.45069681480527 431.8484044633806\n","48: 387.92030496895313 49.67745865508914 437.5977636240423\n","49: 378.92329055070877 47.76502101123333 426.6883115619421\n","50: 387.69063683599234 45.47988427057862 433.17052110657096\n","51: 374.8392062559724 48.54007710888982 423.3792833648622\n","52: 384.3800925165415 47.19482807442546 431.57492059096694\n","53: 383.63795164972544 44.28998462483287 427.9279362745583\n","54: 383.84466303884983 46.003541227430105 429.84820426627994\n","55: 374.5231104120612 45.73854107782245 420.26165148988366\n","56: 395.0608562603593 43.395297683775425 438.4561539441347\n","57: 382.6154066771269 43.2564909607172 425.8718976378441\n","58: 383.17018101364374 45.84726393222809 429.01744494587183\n","59: 382.85635336488485 44.599297404289246 427.4556507691741\n","60: 373.6130275428295 44.11715440452099 417.7301819473505\n","61: 385.23746428638697 43.62371485494077 428.86117914132774\n","62: 374.82539185136557 42.88051278144121 417.7059046328068\n","63: 378.85593362152576 41.10369589924812 419.9596295207739\n","64: 369.7247217968106 44.072639767080545 413.7973615638912\n","65: 390.26739666610956 41.47860461100936 431.7460012771189\n","66: 370.48309944570065 41.405108872801065 411.8882083185017\n","67: 376.73651276528835 42.451246639713645 419.187759405002\n","68: 371.304748121649 42.763070521876216 414.06781864352524\n","69: 391.4989848136902 39.5535382963717 431.0525231100619\n","70: 378.63487707078457 41.08833919279277 419.72321626357734\n","71: 368.84872998297215 41.51525050215423 410.3639804851264\n","72: 366.56152948737144 42.875156711786985 409.43668619915843\n","73: 363.8574204072356 41.485854951664805 405.3432753589004\n","74: 381.2673192024231 39.95574552193284 421.22306472435594\n","75: 369.00544722378254 39.44751432724297 408.4529615510255\n","76: 378.763670809567 40.59782451763749 419.36149532720447\n","77: 376.751048207283 39.72682885453105 416.47787706181407\n","78: 368.9300258755684 39.57361938804388 408.50364526361227\n","79: 375.9175504297018 37.78526488319039 413.7028153128922\n","80: 377.6849834099412 39.11854335665703 416.8035267665982\n","81: 372.7413904517889 37.48645391315222 410.2278443649411\n","82: 371.732988640666 39.23135448247194 410.96434312313795\n","83: 367.85266064852476 38.14292251318693 405.9955831617117\n","84: 367.85385216772556 38.06890215538442 405.92275432311\n","85: 376.3898264542222 37.700049528852105 414.0898759830743\n","86: 380.8442404605448 37.94477483071387 418.7890152912587\n","87: 369.62999138236046 37.75819272175431 407.38818410411477\n","88: 377.9137320294976 37.318121537566185 415.2318535670638\n","89: 373.36441557854414 39.500319074839354 412.8647346533835\n","90: 378.5909330993891 36.84173699840903 415.4326700977981\n","91: 369.9714339375496 37.95338780619204 407.92482174374163\n","92: 367.79221388697624 38.300577307119966 406.0927911940962\n","93: 375.034481048584 37.66688174754381 412.7013627961278\n","94: 362.5147967636585 38.89856633543968 401.4133630990982\n","95: 380.90234104171395 35.66646369732916 416.5688047390431\n","96: 362.35172897577286 38.50683765672147 400.85856663249433\n","97: 363.2593213096261 37.67774065770209 400.9370619673282\n","98: 361.4202926978469 37.426062151789665 398.84635484963655\n","99: 354.6960131302476 36.938593089580536 391.63460621982813\n","100: 353.52428389247507 18.79348373040557 372.31776762288064\n","101: 341.0001342119649 12.206034246832132 353.20616845879704\n","102: 323.0532701201737 10.9695645570755 334.0228346772492\n","103: 327.56186607666314 10.28048145165667 337.8423475283198\n","104: 325.3413415234536 9.353601089678705 334.6949426131323\n","105: 315.12538666650653 8.734168224036694 323.8595548905432\n","106: 327.0691551864147 8.468680154532194 335.5378353409469\n","107: 321.2648125742562 8.049636417999864 329.3144489922561\n","108: 323.9217941351235 7.925263498909771 331.84705763403326\n","109: 318.83593999035656 7.705172515008599 326.54111250536516\n","110: 312.725986238569 7.4678002977743745 320.1937865363434\n","111: 318.6053758561611 7.320266265887767 325.9256421220489\n","112: 318.6269921567291 7.1438142522238195 325.7708064089529\n","113: 316.71674821712077 6.9617849863134325 323.6785332034342\n","114: 310.09453103505075 6.830775843001902 316.92530687805265\n","115: 319.9215973801911 6.702660638373345 326.62425801856443\n","116: 312.5135906538926 6.878936571069062 319.39252722496167\n","117: 315.4694361127913 6.568480762653053 322.03791687544435\n","118: 326.7137999981642 6.722672739997506 333.4364727381617\n","119: 303.4393529081717 6.396932136267424 309.83628504443914\n","120: 305.33244985714555 6.267229102551937 311.5996789596975\n","121: 312.73660358786583 6.054337617941201 318.79094120580703\n","122: 318.6119744889438 6.159017162397504 324.7709916513413\n","123: 314.8026155978441 6.2833944275043905 321.0860100253485\n","124: 305.4314426574856 5.950924367643893 311.3823670251295\n","125: 306.981796534732 5.912633292376995 312.894429827109\n","126: 321.39480525255203 5.927222573198378 327.3220278257504\n","127: 308.44953260943294 5.930672284215689 314.3802048936486\n","128: 315.23794993013144 5.826990033965558 321.064939964097\n","129: 307.99997964221984 5.821618588175625 313.82159823039547\n","130: 292.745462837629 5.751698922831565 298.4971617604606\n","131: 319.1164960116148 5.97922196588479 325.0957179774996\n","132: 305.1065063299611 5.64031727751717 310.7468236074783\n","133: 303.1194962626323 5.464638914447278 308.5841351770796\n","134: 311.87873266637325 5.621453453786671 317.5001861201599\n","135: 304.7672977242619 5.552914296509698 310.3202120207716\n","136: 307.0337296910584 5.666257456643507 312.6999871477019\n","137: 295.43170758523047 5.420518743107095 300.85222632833757\n","138: 292.1046077935025 5.619590146001428 297.72419793950394\n","139: 307.90696908626705 5.506421992089599 313.41339107835665\n","140: 297.9535724669695 5.553556048311293 303.5071285152808\n","141: 306.55743227899075 5.335748812649399 311.89318109164014\n","142: 302.81582327000797 5.429614172317088 308.24543744232506\n","143: 300.57978723198175 5.318088231608272 305.89787546359\n","144: 295.9680371694267 5.165449257241562 301.13348642666824\n","145: 298.493190318346 5.2443188552279025 303.7375091735739\n","146: 315.37453462556005 5.363495811354369 320.7380304369144\n","147: 309.9979439806193 5.34906187071465 315.34700585133396\n","148: 302.0372773706913 5.178510025143623 307.2157873958349\n","149: 299.3440181366168 5.366098111961037 304.71011624857783\n","150: 308.68502816930413 5.466995933558792 314.1520241028629\n","151: 301.78628649935126 5.1214116658084095 306.9076981651597\n","152: 310.1879607196897 5.253412403864786 315.4413731235545\n","153: 296.2057399302721 5.2243814575485885 301.4301213878207\n","154: 300.9233875758946 5.114008519565687 306.0373960954603\n","155: 293.93784551508725 5.273554584477097 299.21140009956434\n","156: 302.2058198489249 5.016415869584307 307.2222357185092\n","157: 304.55456822458655 5.134667980019003 309.68923620460555\n","158: 302.675717420876 5.196396437939256 307.8721138588153\n","159: 305.9977753739804 5.0983165968209505 311.09609197080135\n","160: 292.78113310877234 4.958158017368987 297.7392911261413\n","161: 292.14749596454203 5.094122699927539 297.24161866446957\n","162: 308.99716897681355 5.081873961025849 314.0790429378394\n","163: 302.86480807326734 5.016174849588424 307.88098292285576\n","164: 292.87254859227687 4.944718932500109 297.817267524777\n","165: 297.76767405308783 4.9306893814355135 302.69836343452334\n","166: 305.99499386921525 5.257801505504176 311.2527953747194\n","167: 300.78202016465366 5.081185107817873 305.86320527247153\n","168: 297.7830720692873 5.07204967411235 302.85512174339965\n","169: 297.07879550242797 5.070791749283671 302.14958725171164\n","170: 305.34826405346394 5.127410640474409 310.47567469393834\n","171: 296.1646240334958 4.922154708299786 301.08677874179557\n","172: 289.7382493298501 4.972669153939933 294.71091848379\n","173: 282.64608389046043 5.05308528454043 287.69916917500086\n","174: 302.6260826950893 4.927449986804277 307.55353268189356\n","175: 297.1026709135622 4.894714100752026 301.9973850143142\n","176: 292.60023682937026 4.963898414047435 297.5641352434177\n","177: 297.70057869143784 4.957148008747026 302.65772670018487\n","178: 308.44519230816513 5.031504487153143 313.4766967953183\n","179: 298.30641657393426 4.920657323207706 303.22707389714196\n","180: 296.82312280125916 5.097462988225743 301.9205857894849\n","181: 305.5892311632633 4.879836711334065 310.4690678745974\n","182: 302.5036165677011 5.074786191340536 307.57840275904164\n","183: 301.31231892760843 4.841498795663938 306.15381772327237\n","184: 285.1043472411111 4.984141721623018 290.0884889627341\n","185: 302.86123025789857 4.9725614711642265 307.8337917290628\n","186: 297.5214220583439 5.1383815326262265 302.6598035909701\n","187: 296.3082247301936 5.06386146415025 301.37208619434386\n","188: 284.9284234046936 5.115795524790883 290.0442189294845\n","189: 296.2967043919489 4.999312887899578 301.29601727984846\n","190: 301.11685417219996 4.833547202171758 305.9504013743717\n","191: 291.2097855997272 4.595458751777187 295.80524435150437\n","192: 290.9146211575717 4.8310856954194605 295.74570685299113\n","193: 293.86993444524705 4.894241367466748 298.7641758127138\n","194: 285.0983053855598 5.022231136681512 290.1205365222413\n","195: 298.66903011500835 4.874598917551339 303.5436290325597\n","196: 303.86818021163344 5.0157746721524745 308.8839548837859\n","197: 309.53597006574273 4.665427060099319 314.20139712584205\n","198: 297.67753318324685 4.8435516487807035 302.52108483202755\n","199: 297.3594406154007 4.94845290761441 302.3078935230151\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"doR5kS81SW5F"},"source":["# Save model"],"id":"doR5kS81SW5F"},{"cell_type":"code","metadata":{"id":"frozen-damage"},"source":["# torch.save(model.state_dict(), './mixup_model_pytorch_cifar10')\n","# model = models.__dict__['ResNet18']()\n","# model.load_state_dict(torch.load('./mixup_model_pytorch_cifar10'))"],"id":"frozen-damage","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLlLnmpRSZAl"},"source":["# Test on Test Data"],"id":"BLlLnmpRSZAl"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aboriginal-lafayette","executionInfo":{"status":"ok","timestamp":1625003243407,"user_tz":-60,"elapsed":3920,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"cb1f0933-b5f3-4887-e595-d196922c23d6"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"aboriginal-lafayette","execution_count":null,"outputs":[{"output_type":"stream","text":["0.9565\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xHj0XxoMScbg"},"source":["# Test on Train Data"],"id":"xHj0XxoMScbg"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"therapeutic-orlando","executionInfo":{"status":"ok","timestamp":1625003270451,"user_tz":-60,"elapsed":27047,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"ab51e586-c98b-429d-a20f-b41ca4f3b929"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"therapeutic-orlando","execution_count":null,"outputs":[{"output_type":"stream","text":["0.99986\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XCvQUWwMSetI"},"source":[""],"id":"XCvQUWwMSetI","execution_count":null,"outputs":[]}]}