{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"mixup breast NN sc.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NyrKck5mLTzj"},"source":["# Import Libraries"],"id":"NyrKck5mLTzj"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"proprietary-livestock","executionInfo":{"status":"ok","timestamp":1625079395660,"user_tz":-60,"elapsed":19376,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"ec9382f9-5c2b-450f-f3b7-d81953b6ef0c"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"proprietary-livestock","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GFBzaRxYLmIz"},"source":["# Import outside code"],"id":"GFBzaRxYLmIz"},{"cell_type":"code","metadata":{"id":"mSeLSa5KLn_5","executionInfo":{"status":"ok","timestamp":1625079396372,"user_tz":-60,"elapsed":715,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"mSeLSa5KLn_5","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"KU2jvzwwLn5W","executionInfo":{"status":"ok","timestamp":1625079396667,"user_tz":-60,"elapsed":298,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"KU2jvzwwLn5W","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o5PtGmQoLrl7"},"source":["# Configuration"],"id":"o5PtGmQoLrl7"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"silent-johns","executionInfo":{"status":"ok","timestamp":1625079396668,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"992b74d7-a5e5-4376-c738-ed6f64375466"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","batch_size = 128\n","step_size = 0.005\n","random_seed = 0\n","epochs = 300\n","L2_decay = 1e-4\n","alpha = 1.\n","\n","torch.manual_seed(random_seed)"],"id":"silent-johns","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fdb4eebfa50>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"NRldvRO1L28r"},"source":["# Data"],"id":"NRldvRO1L28r"},{"cell_type":"code","metadata":{"id":"compressed-schedule","executionInfo":{"status":"ok","timestamp":1625079396857,"user_tz":-60,"elapsed":192,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["train_data, train_labels, val_data, val_labels, test_data, test_labels = load_skl_data('breast_cancer')\n","test_data = np.vstack((val_data, test_data))\n","test_labels = np.hstack((val_labels, test_labels))\n","train_data = torch.from_numpy(train_data).type(torch.FloatTensor)\n","train_labels = torch.from_numpy(train_labels)\n","test_data = torch.from_numpy(test_data).type(torch.FloatTensor)\n","test_labels = torch.from_numpy(test_labels)\n","train_mean = torch.mean(train_data, 0)\n","train_std = torch.std(train_data, 0)\n","train_data = (train_data - train_mean) / train_std\n","test_data = (test_data - train_mean) / train_std\n","train_set = torch.utils.data.TensorDataset(train_data, train_labels)\n","test_set = torch.utils.data.TensorDataset(test_data, test_labels)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"compressed-schedule","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6loof5Y_L6ry"},"source":["# Model, Loss, Optimiser"],"id":"6loof5Y_L6ry"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buried-science","executionInfo":{"status":"ok","timestamp":1625079403133,"user_tz":-60,"elapsed":6277,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"81443d78-bac9-4f68-f53b-b9316507e0a4"},"source":["class fc_model(nn.Module):\n","    def __init__(self):\n","        super(fc_model, self).__init__()\n","        self.fc1 = nn.Linear(30, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 1)\n","    def forward(self, inputs):\n","        fc1_out = F.tanh(self.fc1(inputs))\n","        fc2_out = F.tanh(self.fc2(fc1_out))\n","        fc3_out = F.tanh(self.fc3(fc2_out))\n","        fc4_out = self.fc4(fc3_out)\n","        return fc4_out\n","\n","model = fc_model()\n","criterion = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"buried-science","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["fc_model(\n","  (fc1): Linear(in_features=30, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=32, bias=True)\n","  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"kaMBwZHaMIRn"},"source":["# Data Augmentation / Perturbation AND corresponding loss"],"id":"kaMBwZHaMIRn"},{"cell_type":"code","metadata":{"id":"aUta5merRfYp","executionInfo":{"status":"ok","timestamp":1625079403134,"user_tz":-60,"elapsed":9,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_breast_sc(inputs, labels, alpha):\n","    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample().to('cuda')\n","    mixup_inputs_uc_list = list()\n","    labels_uc_list = list()\n","    unique_classes = torch.unique(labels)\n","    for uc in unique_classes:\n","        mask_uc = (labels == uc).flatten()  # flatten to avoid the labels are in column vector\n","        inputs_uc = inputs[mask_uc]\n","        labels_uc = labels[mask_uc]\n","        batch_size_uc = labels_uc.size(0)\n","        idx = torch.randperm(batch_size_uc).to('cuda')\n","        mixup_inputs_uc = lmbda * inputs_uc + (1 - lmbda) * inputs_uc[idx]\n","        mixup_inputs_uc_list.append(mixup_inputs_uc)\n","        labels_uc_list.append(labels_uc)\n","    mixup_inputs_sc = torch.vstack(mixup_inputs_uc_list)\n","    mixup_labels_sc = torch.cat(labels_uc_list, dim=0)  # use cat not hstack to avoid labels are in column vector\n","    return mixup_inputs_sc, mixup_labels_sc, lmbda"],"id":"aUta5merRfYp","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQOqDOmDMYOj"},"source":["# Training"],"id":"SQOqDOmDMYOj"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pediatric-namibia","executionInfo":{"status":"ok","timestamp":1625079405822,"user_tz":-60,"elapsed":2696,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"8d99ac1d-3976-4417-a6d5-eac135bedb89"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","\n","        # Mixup with same class #\n","        mixup_inputs_sc, mixup_labels_sc, lmbda = mixup_breast_sc(inputs, labels, alpha)\n","        mixup_outputs_sc = model(mixup_inputs_sc)\n","        mixup_loss_sc = criterion(mixup_outputs_sc, mixup_labels_sc)  # no need to mix the loss up since it is now mixup with same class, just use ordinary cross entropy\n","\n","        # Record #\n","        epoch_loss += mixup_loss_sc.item()\n","\n","        # Gradient Calculation & Optimisation #\n","        mixup_loss_sc.backward()\n","        optimizer.step()\n","    \n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print loss #\n","    print('{}: {}'.format(epoch, epoch_loss))"],"id":"pediatric-namibia","execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["0: 2.1228859424591064\n","1: 2.088274300098419\n","2: 2.0312176942825317\n","3: 1.9499748349189758\n","4: 1.8635739088058472\n","5: 1.7746054530143738\n","6: 1.668950080871582\n","7: 1.5522698760032654\n","8: 1.45877406001091\n","9: 1.3340509533882141\n","10: 1.1768344342708588\n","11: 1.056058645248413\n","12: 0.9491170644760132\n","13: 0.8269743770360947\n","14: 0.7514345049858093\n","15: 0.6502001881599426\n","16: 0.555307000875473\n","17: 0.5291041135787964\n","18: 0.5305146425962448\n","19: 0.49538639187812805\n","20: 0.3881790116429329\n","21: 0.3997773751616478\n","22: 0.30057084560394287\n","23: 0.3111655116081238\n","24: 0.24943498894572258\n","25: 0.2821086123585701\n","26: 0.32209954783320427\n","27: 0.20635703206062317\n","28: 0.27657873928546906\n","29: 0.2591194696724415\n","30: 0.16803806647658348\n","31: 0.24737711995840073\n","32: 0.15821220353245735\n","33: 0.2678072787821293\n","34: 0.25613193586468697\n","35: 0.12156777828931808\n","36: 0.2235737219452858\n","37: 0.20811138302087784\n","38: 0.20132774487137794\n","39: 0.19956108555197716\n","40: 0.1952758990228176\n","41: 0.11585426330566406\n","42: 0.14955616742372513\n","43: 0.15220559015870094\n","44: 0.15889883786439896\n","45: 0.17444984056055546\n","46: 0.17487787827849388\n","47: 0.13331085816025734\n","48: 0.17333362624049187\n","49: 0.15373747795820236\n","50: 0.1026986576616764\n","51: 0.12535160034894943\n","52: 0.15262677893042564\n","53: 0.14340337552130222\n","54: 0.12102603167295456\n","55: 0.16230391710996628\n","56: 0.1320863626897335\n","57: 0.13448171876370907\n","58: 0.07689018361270428\n","59: 0.12346740253269672\n","60: 0.10433824919164181\n","61: 0.10362635925412178\n","62: 0.07922665029764175\n","63: 0.18582968600094318\n","64: 0.12232226878404617\n","65: 0.10036313906311989\n","66: 0.16529693454504013\n","67: 0.1282623838633299\n","68: 0.13110285252332687\n","69: 0.06381905451416969\n","70: 0.10468931868672371\n","71: 0.0826911423355341\n","72: 0.12587628979235888\n","73: 0.12451570108532906\n","74: 0.10701464302837849\n","75: 0.1335915569216013\n","76: 0.09024861454963684\n","77: 0.07719683647155762\n","78: 0.1816935557872057\n","79: 0.12128672003746033\n","80: 0.15273246727883816\n","81: 0.08579865004867315\n","82: 0.0945968721061945\n","83: 0.06293453369289637\n","84: 0.09333656169474125\n","85: 0.08456671051681042\n","86: 0.06250499002635479\n","87: 0.13790485635399818\n","88: 0.07032905239611864\n","89: 0.08813411369919777\n","90: 0.09043105691671371\n","91: 0.09991091303527355\n","92: 0.09718051832169294\n","93: 0.15384800545871258\n","94: 0.1414220593869686\n","95: 0.1166209988296032\n","96: 0.12921406421810389\n","97: 0.08580746315419674\n","98: 0.03423507045954466\n","99: 0.09151565469801426\n","100: 0.10125319845974445\n","101: 0.05469823349267244\n","102: 0.0400376096367836\n","103: 0.03804174158722162\n","104: 0.10616329498589039\n","105: 0.06253219302743673\n","106: 0.06298824306577444\n","107: 0.052007358986884356\n","108: 0.10392712615430355\n","109: 0.05224922485649586\n","110: 0.06253048777580261\n","111: 0.08905802434310317\n","112: 0.07323756301775575\n","113: 0.10606283135712147\n","114: 0.15909799188375473\n","115: 0.09001314081251621\n","116: 0.07612030114978552\n","117: 0.1537685366347432\n","118: 0.06600759504362941\n","119: 0.09790833946317434\n","120: 0.15979154780507088\n","121: 0.12197305075824261\n","122: 0.14558946527540684\n","123: 0.05534305330365896\n","124: 0.1448404281400144\n","125: 0.11522583290934563\n","126: 0.1051623560488224\n","127: 0.13315075635910034\n","128: 0.07401330396533012\n","129: 0.11554791033267975\n","130: 0.11642614379525185\n","131: 0.07874387688934803\n","132: 0.11305432766675949\n","133: 0.09208073699846864\n","134: 0.030055904760956764\n","135: 0.08545456733554602\n","136: 0.13432800490409136\n","137: 0.11636631563305855\n","138: 0.08892328292131424\n","139: 0.08365787239745259\n","140: 0.07277006469666958\n","141: 0.05707404296845198\n","142: 0.06797774601727724\n","143: 0.08437321148812771\n","144: 0.06439680559560657\n","145: 0.10743117518723011\n","146: 0.09410693449899554\n","147: 0.06063081510365009\n","148: 0.06479869689792395\n","149: 0.08108159899711609\n","150: 0.15206406638026237\n","151: 0.07745810970664024\n","152: 0.14948393311351538\n","153: 0.11952581442892551\n","154: 0.11745757889002562\n","155: 0.10161762218922377\n","156: 0.09950930904597044\n","157: 0.11108887009322643\n","158: 0.1461557075381279\n","159: 0.09094481589272618\n","160: 0.06241445895284414\n","161: 0.12266251258552074\n","162: 0.09140606969594955\n","163: 0.10363647108897567\n","164: 0.07553127780556679\n","165: 0.07974845357239246\n","166: 0.0944924633949995\n","167: 0.1367054060101509\n","168: 0.04705338133499026\n","169: 0.07391867600381374\n","170: 0.060338363982737064\n","171: 0.060149531811475754\n","172: 0.16553919948637486\n","173: 0.12239732220768929\n","174: 0.10560958925634623\n","175: 0.061247737146914005\n","176: 0.09786145016551018\n","177: 0.08332204073667526\n","178: 0.10045918356627226\n","179: 0.07725343760102987\n","180: 0.026943098288029432\n","181: 0.026650771498680115\n","182: 0.08303100243210793\n","183: 0.06763933785259724\n","184: 0.10913682170212269\n","185: 0.028630652464926243\n","186: 0.07617936795577407\n","187: 0.08473278675228357\n","188: 0.051462266594171524\n","189: 0.16112766414880753\n","190: 0.08743108808994293\n","191: 0.097225621342659\n","192: 0.05134354578331113\n","193: 0.04219532757997513\n","194: 0.0718229953199625\n","195: 0.08679170068353415\n","196: 0.06618645275011659\n","197: 0.12563986517488956\n","198: 0.09255144512280822\n","199: 0.116720175370574\n","200: 0.10112437419593334\n","201: 0.10341623146086931\n","202: 0.0782155729830265\n","203: 0.09020254015922546\n","204: 0.0343271535821259\n","205: 0.04711394617334008\n","206: 0.13093887083232403\n","207: 0.08226866973564029\n","208: 0.1246294416487217\n","209: 0.08929568529129028\n","210: 0.10077922977507114\n","211: 0.06108509097248316\n","212: 0.08808853011578321\n","213: 0.10712654609233141\n","214: 0.08048676094040275\n","215: 0.06194890849292278\n","216: 0.08546396158635616\n","217: 0.019191020634025335\n","218: 0.05319737084209919\n","219: 0.0883279386907816\n","220: 0.06518135592341423\n","221: 0.09674962749704719\n","222: 0.04732810007408261\n","223: 0.05051972111687064\n","224: 0.08418987086042762\n","225: 0.11339326575398445\n","226: 0.07012952002696693\n","227: 0.09180822875350714\n","228: 0.07423464953899384\n","229: 0.060510922223329544\n","230: 0.07613946124911308\n","231: 0.07507660333067179\n","232: 0.031100464053452015\n","233: 0.06711280159652233\n","234: 0.048511311411857605\n","235: 0.10876476764678955\n","236: 0.03803119109943509\n","237: 0.0831511951982975\n","238: 0.06258776690810919\n","239: 0.12735413946211338\n","240: 0.06384062254801393\n","241: 0.051502577029168606\n","242: 0.14258761890232563\n","243: 0.0633733905851841\n","244: 0.08026824612170458\n","245: 0.12036945298314095\n","246: 0.06188327074050903\n","247: 0.08222166076302528\n","248: 0.11772476369515061\n","249: 0.043574096634984016\n","250: 0.07610439136624336\n","251: 0.04552691150456667\n","252: 0.02634123247116804\n","253: 0.13736969232559204\n","254: 0.08068811753764749\n","255: 0.05412287171930075\n","256: 0.041566099505871534\n","257: 0.05610945215448737\n","258: 0.12578295171260834\n","259: 0.08896571677178144\n","260: 0.07429992780089378\n","261: 0.0994305731728673\n","262: 0.03918787511065602\n","263: 0.04080522479489446\n","264: 0.14455370232462883\n","265: 0.15628546895459294\n","266: 0.057438045740127563\n","267: 0.050092491786926985\n","268: 0.1315011102706194\n","269: 0.07171057723462582\n","270: 0.025826236233115196\n","271: 0.07115144655108452\n","272: 0.0657824301160872\n","273: 0.04656088259071112\n","274: 0.07082193344831467\n","275: 0.12108712643384933\n","276: 0.06597555428743362\n","277: 0.18015240877866745\n","278: 0.1124974163249135\n","279: 0.08233095705509186\n","280: 0.12946569314226508\n","281: 0.08806815044954419\n","282: 0.0591103951446712\n","283: 0.0963958203792572\n","284: 0.12355792662128806\n","285: 0.023743048310279846\n","286: 0.06180888973176479\n","287: 0.05060280114412308\n","288: 0.13528649881482124\n","289: 0.09020233526825905\n","290: 0.0467825043015182\n","291: 0.029488634318113327\n","292: 0.08481862396001816\n","293: 0.07528094155713916\n","294: 0.08448081696406007\n","295: 0.08703487971797585\n","296: 0.04003599192947149\n","297: 0.11008296813815832\n","298: 0.1097891516983509\n","299: 0.10456656478345394\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CL1h58tJNu56"},"source":["# Save model"],"id":"CL1h58tJNu56"},{"cell_type":"code","metadata":{"id":"brief-details","executionInfo":{"status":"ok","timestamp":1625079405822,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["# torch.save(model.state_dict(), './mixup_model_pytorch_breast')\n","# model = fc_model()\n","# model.load_state_dict(torch.load('./mixup_model_pytorch_breast'))"],"id":"brief-details","execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DydYzZprNxjA"},"source":["# Test on Test Data"],"id":"DydYzZprNxjA"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"latin-interest","executionInfo":{"status":"ok","timestamp":1625079405822,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"8f0e41c4-c335-47dd-f0eb-4c5d19e13f66"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","        outputs = model(inputs)\n","        predicts = (torch.sign(outputs) + 1) / 2\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"latin-interest","execution_count":10,"outputs":[{"output_type":"stream","text":["0.9780701754385965\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"YLVUq0LdNzfq"},"source":["# Test on Train Data"],"id":"YLVUq0LdNzfq"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"resident-overall","executionInfo":{"status":"ok","timestamp":1625079405823,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"f7696de0-d0da-4f40-e7d5-ba09b609ebf8"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n","        outputs = model(inputs)\n","        predicts = (torch.sign(outputs) + 1) / 2\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"resident-overall","execution_count":11,"outputs":[{"output_type":"stream","text":["0.9765395894428153\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"preceding-galaxy","executionInfo":{"status":"ok","timestamp":1625079405824,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":[""],"id":"preceding-galaxy","execution_count":11,"outputs":[]}]}