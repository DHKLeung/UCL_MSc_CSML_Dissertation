{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"mixup MNIST NN nb0.5 aug WPL0.75.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CQiI9vfjUCRv"},"source":["# Import Libraries"],"id":"CQiI9vfjUCRv"},{"cell_type":"code","metadata":{"id":"continental-platform","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261108793,"user_tz":-60,"elapsed":32471,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"3a6b700e-3261-4107-b6e8-f549b2449b5c"},"source":["import torch\n","from torchvision import transforms, datasets, models\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"continental-platform","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"26gu3pGHURua"},"source":["# Import outside code"],"id":"26gu3pGHURua"},{"cell_type":"code","metadata":{"id":"PIrwJQD8UVLK","executionInfo":{"status":"ok","timestamp":1625261109999,"user_tz":-60,"elapsed":1208,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"PIrwJQD8UVLK","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqYQ_uo1UVEA","executionInfo":{"status":"ok","timestamp":1625261110000,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"MqYQ_uo1UVEA","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sH8eHg8UbTJ"},"source":["# Configuration"],"id":"6sH8eHg8UbTJ"},{"cell_type":"code","metadata":{"id":"cultural-recorder","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261110001,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"8352ab2c-7c2b-4531-80e6-1765603e468c"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","batch_size = 128\n","step_size = 0.01\n","random_seed = 0\n","epochs = 100\n","L2_decay = 1e-4\n","alpha = 1.\n","geometric_param = 0.5\n","perturb_loss_weight = 0.75\n","\n","torch.manual_seed(random_seed)"],"id":"cultural-recorder","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f86653a9ab0>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"Bc0p64pfU10K"},"source":["# Data"],"id":"Bc0p64pfU10K"},{"cell_type":"code","metadata":{"id":"international-retailer","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261115907,"user_tz":-60,"elapsed":5515,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"147c6446-f823-4484-cc34-6a5bc25431c8"},"source":["\"\"\"\n","Data\n","\"\"\"\n","train_set = datasets.MNIST(root='/content/gdrive/My Drive/colab', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_set = datasets.MNIST(root='/content/gdrive/My Drive/colab', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"international-retailer","execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"p9kXmAOAVAnr"},"source":["# Models, Loss, Optimiser"],"id":"p9kXmAOAVAnr"},{"cell_type":"code","metadata":{"id":"brown-employee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261122855,"user_tz":-60,"elapsed":6951,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"d425653a-4b6b-40ba-fa36-a295bc537043"},"source":["model = models.resnet18(pretrained=False)\n","for param in model.parameters():\n","    param.requires_grad = True\n","model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n","model.fc = torch.nn.Linear(512, 10)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"brown-employee","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"srXckx9OXhfr"},"source":["# Data Augmentation / Perturbation AND corresponding loss"],"id":"srXckx9OXhfr"},{"cell_type":"code","metadata":{"id":"tgW61zPwOLn3","executionInfo":{"status":"ok","timestamp":1625261122855,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_MNIST_nb(inputs, labels, geometric_param, alpha):\n","    inner_batch_size = labels.size(0)\n","    inputs_flatten = inputs.reshape(inner_batch_size, -1)\n","\n","    # Compute pair-wise distances & sort the distances #\n","    dists = torch.cdist(inputs_flatten, inputs_flatten)\n","    sort_idx = torch.argsort(dists, dim=1)\n","    sort_idx_no_itself = sort_idx[:, 1:]\n","\n","    # Generate geometric random variables for selecting neighbours & get the index of selected neighbour data #\n","    select_idx = torch.distributions.geometric.Geometric(geometric_param).sample_n(inner_batch_size).type(torch.LongTensor).to('cuda')\n","    select_idx_clipped = torch.clamp(select_idx, max=inner_batch_size - 2)\n","    nb_idx = sort_idx_no_itself[torch.arange(inner_batch_size), select_idx_clipped]\n","\n","    # mixup with neighbours #\n","    inputs_nb = inputs[nb_idx]\n","    labels_nb = labels[nb_idx]\n","    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample().to('cuda')\n","    mixup_inputs_nb = lmbda * inputs + (1 - lmbda) * inputs_nb\n","    return mixup_inputs_nb, labels, labels_nb, lmbda"],"id":"tgW61zPwOLn3","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"democratic-smooth","executionInfo":{"status":"ok","timestamp":1625261122856,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n","    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n","    return mixup_loss"],"id":"democratic-smooth","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntv024FgYDzh"},"source":["# Training"],"id":"ntv024FgYDzh"},{"cell_type":"code","metadata":{"id":"adaptive-short","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625262395535,"user_tz":-60,"elapsed":1272683,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"bce937ec-9278-47d2-e327-c114cbe99a90"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_mixup_loss = 0.\n","    epoch_loss = 0.\n","    epoch_augment_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","\n","        # Mixup with random neighbour perturbation #\n","        mixup_inputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda = mixup_MNIST_nb(inputs, labels, geometric_param, alpha)\n","        \n","        # Concatenate perturbation and original data, to do augmentation and loss computation #\n","        original_num = inputs.size(0)\n","        augment_inputs = torch.vstack((inputs, mixup_inputs_nb))\n","        augment_outputs = model(augment_inputs)\n","        outputs = augment_outputs[:original_num]\n","        mixup_outputs_nb = augment_outputs[original_num:]\n","        mixup_loss_nb = mixup_criterion(criterion, mixup_outputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda)\n","        loss = criterion(outputs, labels)\n","        weighted_augment_loss = perturb_loss_weight * mixup_loss_nb + (1 - perturb_loss_weight) * loss\n","\n","        # Record #\n","        epoch_mixup_loss += mixup_loss_nb.item()\n","        epoch_loss += loss.item()\n","        epoch_augment_loss += (mixup_loss_nb.item() + loss.item())\n","\n","        # Gradient Calculation & Optimisation #\n","        weighted_augment_loss.backward()\n","        optimizer.step()\n","    \n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print decomposed losses #\n","    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_loss, epoch_augment_loss))"],"id":"adaptive-short","execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:151: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n","  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["0: 194.77646240219474 67.72582189366221 262.50228429585695\n","1: 151.15651232004166 21.268047930207103 172.42456025024876\n","2: 144.12283724546432 14.414834740106016 158.53767198557034\n","3: 137.52679582312703 10.729879407212138 148.25667523033917\n","4: 133.1048415666446 8.51427082810551 141.61911239475012\n","5: 132.5171000547707 7.476750096306205 139.9938501510769\n","6: 129.77335258293897 6.1847286452539265 135.9580812281929\n","7: 126.11570193246007 5.407917017815635 131.5236189502757\n","8: 125.74220262281597 4.687178636086173 130.42938125890214\n","9: 124.38359315227717 4.002884023124352 128.38647717540152\n","10: 122.51532406173646 3.6548970638541505 126.17022112559061\n","11: 122.52778996527195 3.511343884281814 126.03913384955376\n","12: 118.9588348325342 3.322092982940376 122.28092781547457\n","13: 122.03427657857537 2.8677270364714786 124.90200361504685\n","14: 119.70299657434225 2.8899583948077634 122.59295496915001\n","15: 118.54782918468118 2.511952645436395 121.05978183011757\n","16: 115.71390680875629 2.4636987076955847 118.17760551645188\n","17: 117.89412507787347 2.2322071412345394 120.12633221910801\n","18: 117.43454050924629 2.195828377676662 119.63036888692295\n","19: 118.77151686511934 2.1320662408252247 120.90358310594456\n","20: 113.75649967975914 2.107808790053241 115.86430846981239\n","21: 114.3152807354927 1.9442336027277634 116.25951433822047\n","22: 114.88395745959133 1.8041894931229763 116.6881469527143\n","23: 114.05259853508323 2.0082458893884905 116.06084442447172\n","24: 115.24327403493226 1.8414236917160451 117.0846977266483\n","25: 113.64907240308821 1.6832578920875676 115.33233029517578\n","26: 115.95099825784564 2.2125211275415495 118.16351938538719\n","27: 113.37909993901849 1.6610910242307 115.04019096324919\n","28: 110.81709619332105 1.6454679148737341 112.46256410819478\n","29: 112.97291383892298 1.6074204344768077 114.58033427339979\n","30: 112.29461253108457 1.7271282481960952 114.02174077928066\n","31: 110.45828609727323 1.5019926290260628 111.9602787262993\n","32: 111.40899567026645 1.4267298156337347 112.83572548590018\n","33: 109.26410870533437 1.388368233689107 110.65247693902347\n","34: 112.76362880691886 1.4657525946386158 114.22938140155748\n","35: 110.1795658711344 1.380843656428624 111.56040952756302\n","36: 113.15951345860958 1.3652833979576826 114.52479685656726\n","37: 110.79027847573161 1.2289609694853425 112.01923944521695\n","38: 110.14985871873796 1.2508047583396547 111.40066347707761\n","39: 113.12173074483871 1.1586185978958383 114.28034934273455\n","40: 108.8778670700267 1.3275846812466625 110.20545175127336\n","41: 110.82887638639659 1.1701706685707904 111.99904705496738\n","42: 108.45296837948263 1.198136671911925 109.65110505139455\n","43: 107.90029805526137 1.181980095920153 109.08227815118153\n","44: 104.41273116786033 1.2076682631741278 105.62039943103446\n","45: 110.07865414116532 1.0886006204236764 111.16725476158899\n","46: 105.60636387392879 1.168513696116861 106.77487757004565\n","47: 108.93897243682295 1.0603581616887823 109.99933059851173\n","48: 106.95623368769884 1.0199336463410873 107.97616733403993\n","49: 109.36203292477876 1.0217995794664603 110.38383250424522\n","50: 102.1689898762852 0.7956840614206158 102.96467393770581\n","51: 107.9053472825326 0.6571233779541217 108.56247066048672\n","52: 102.52618557959795 0.6877360242942814 103.21392160389223\n","53: 101.26121725421399 0.6845010051329155 101.9457182593469\n","54: 104.14599312189966 0.6473760718654376 104.7933691937651\n","55: 103.79166628280655 0.6464578119921498 104.4381240947987\n","56: 103.9411750799045 0.6398971437884029 104.5810722236929\n","57: 100.57265407405794 0.6795234255550895 101.25217749961303\n","58: 102.42848271876574 0.6695362345199101 103.09801895328565\n","59: 97.87413550820202 0.7184834381041583 98.59261894630617\n","60: 103.51493239961565 0.6340250555076636 104.14895745512331\n","61: 98.33151919441298 0.6820062357001007 99.01352543011308\n","62: 103.58719269745052 0.6255936262896284 104.21278632374015\n","63: 100.76848573610187 0.6187902631645557 101.38727599926642\n","64: 99.6624890952371 0.6601564753509592 100.32264557058807\n","65: 103.73331072740257 0.6016692655102815 104.33497999291285\n","66: 102.8796720826067 0.6259591722046025 103.5056312548113\n","67: 102.18080109311268 0.6343216945242602 102.81512278763694\n","68: 102.5005506966263 0.5974728586734273 103.09802355529973\n","69: 101.22167112259194 0.6146535240113735 101.83632464660332\n","70: 100.64772095996886 0.6168511763971765 101.26457213636604\n","71: 102.67972723394632 0.6025899286323693 103.28231716257869\n","72: 102.53894276916981 0.6097983600920998 103.14874112926191\n","73: 99.02792321052402 0.6512160604179371 99.67913927094196\n","74: 102.39788069576025 0.6232323439035099 103.02111303966376\n","75: 101.82276639528573 0.6006906341353897 102.42345702942112\n","76: 102.82699378626421 0.5925723998516332 103.41956618611584\n","77: 100.96983830444515 0.6161716636270285 101.58600996807218\n","78: 100.32193744927645 0.6230091610632371 100.94494661033968\n","79: 103.90903830900788 0.5781170916452538 104.48715540065314\n","80: 100.21466401591897 0.6463427716225851 100.86100678754156\n","81: 100.73843391146511 0.6047650155669544 101.34319892703206\n","82: 100.80255939438939 0.63297020009486 101.43552959448425\n","83: 100.84292986709625 0.6256044337933417 101.46853430088959\n","84: 101.639725537505 0.6156688241171651 102.25539436162217\n","85: 101.77184213418514 0.6306868972606026 102.40252903144574\n","86: 100.31511410605162 0.6287361339782365 100.94385024002986\n","87: 101.34174937289208 0.6029659413616173 101.9447153142537\n","88: 101.0547367874533 0.5896071649331134 101.64434395238641\n","89: 98.53392112441361 0.6084165932843462 99.14233771769796\n","90: 99.07968307286501 0.619822756096255 99.69950582896126\n","91: 100.66355199180543 0.6132796513556968 101.27683164316113\n","92: 98.61741457600147 0.6228475569223519 99.24026213292382\n","93: 101.2234309464693 0.5868979241931811 101.81032887066249\n","94: 100.08334792312235 0.6159402413468342 100.69928816446918\n","95: 99.74755226261914 0.6049975275818724 100.35254979020101\n","96: 99.74511118326336 0.6053250416880473 100.35043622495141\n","97: 101.49739393312484 0.5763816137914546 102.0737755469163\n","98: 101.95052704028785 0.5883068803232163 102.53883392061107\n","99: 100.77114578383043 0.5957355971622746 101.36688138099271\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_X5YE5kBZ5ao"},"source":["# Save model"],"id":"_X5YE5kBZ5ao"},{"cell_type":"code","metadata":{"id":"armed-contact","executionInfo":{"status":"ok","timestamp":1625262395537,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["# torch.save(model.state_dict(), './mixup_model_pytorch_mnist')\n","# model = models.resnet18(pretrained=False)\n","# model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n","# model.fc = torch.nn.Linear(512, 10)\n","# model.load_state_dict(torch.load('./mixup_model_pytorch_mnist'))"],"id":"armed-contact","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KI0HoDg3Z7sX"},"source":["# Test on Test Data"],"id":"KI0HoDg3Z7sX"},{"cell_type":"code","metadata":{"id":"competitive-penny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625262397608,"user_tz":-60,"elapsed":2081,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"417f2f8b-162c-4f86-b985-8a0cee0d841d"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"competitive-penny","execution_count":11,"outputs":[{"output_type":"stream","text":["0.9939\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4VE_ydjNZ-RY"},"source":["# Test on Train Data"],"id":"4VE_ydjNZ-RY"},{"cell_type":"code","metadata":{"id":"victorian-financing","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625262404617,"user_tz":-60,"elapsed":7015,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"5cec84c4-ae75-4efe-fa12-940a8d5c68de"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"victorian-financing","execution_count":12,"outputs":[{"output_type":"stream","text":["1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"capital-situation","executionInfo":{"status":"ok","timestamp":1625262404618,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":[""],"id":"capital-situation","execution_count":12,"outputs":[]}]}