{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"mixup MNIST NN nb0.5 aug WPL0.25.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CQiI9vfjUCRv"},"source":["# Import Libraries"],"id":"CQiI9vfjUCRv"},{"cell_type":"code","metadata":{"id":"continental-platform","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261099104,"user_tz":-60,"elapsed":24879,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"e05c385f-f418-425f-f0b0-59d17fc5ea8f"},"source":["import torch\n","from torchvision import transforms, datasets, models\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"continental-platform","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"26gu3pGHURua"},"source":["# Import outside code"],"id":"26gu3pGHURua"},{"cell_type":"code","metadata":{"id":"PIrwJQD8UVLK","executionInfo":{"status":"ok","timestamp":1625261100008,"user_tz":-60,"elapsed":906,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"PIrwJQD8UVLK","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqYQ_uo1UVEA","executionInfo":{"status":"ok","timestamp":1625261100395,"user_tz":-60,"elapsed":389,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"MqYQ_uo1UVEA","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sH8eHg8UbTJ"},"source":["# Configuration"],"id":"6sH8eHg8UbTJ"},{"cell_type":"code","metadata":{"id":"cultural-recorder","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261100395,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"aaf0b255-9b6b-493e-bfd6-7c1400ad3051"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","batch_size = 128\n","step_size = 0.01\n","random_seed = 0\n","epochs = 100\n","L2_decay = 1e-4\n","alpha = 1.\n","geometric_param = 0.5\n","perturb_loss_weight = 0.25\n","\n","torch.manual_seed(random_seed)"],"id":"cultural-recorder","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fa3640f3ad0>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"Bc0p64pfU10K"},"source":["# Data"],"id":"Bc0p64pfU10K"},{"cell_type":"code","metadata":{"id":"international-retailer","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261105741,"user_tz":-60,"elapsed":5348,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"21b2d312-ed25-4a31-a1da-7eeb57d36ab9"},"source":["\"\"\"\n","Data\n","\"\"\"\n","train_set = datasets.MNIST(root='/content/gdrive/My Drive/colab', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_set = datasets.MNIST(root='/content/gdrive/My Drive/colab', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"international-retailer","execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"p9kXmAOAVAnr"},"source":["# Models, Loss, Optimiser"],"id":"p9kXmAOAVAnr"},{"cell_type":"code","metadata":{"id":"brown-employee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625261112708,"user_tz":-60,"elapsed":6968,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"5c9da582-adf5-431c-9282-c1ad1667ad4b"},"source":["model = models.resnet18(pretrained=False)\n","for param in model.parameters():\n","    param.requires_grad = True\n","model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n","model.fc = torch.nn.Linear(512, 10)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"brown-employee","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"srXckx9OXhfr"},"source":["# Data Augmentation / Perturbation AND corresponding loss"],"id":"srXckx9OXhfr"},{"cell_type":"code","metadata":{"id":"tgW61zPwOLn3","executionInfo":{"status":"ok","timestamp":1625261112708,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_MNIST_nb(inputs, labels, geometric_param, alpha):\n","    inner_batch_size = labels.size(0)\n","    inputs_flatten = inputs.reshape(inner_batch_size, -1)\n","\n","    # Compute pair-wise distances & sort the distances #\n","    dists = torch.cdist(inputs_flatten, inputs_flatten)\n","    sort_idx = torch.argsort(dists, dim=1)\n","    sort_idx_no_itself = sort_idx[:, 1:]\n","\n","    # Generate geometric random variables for selecting neighbours & get the index of selected neighbour data #\n","    select_idx = torch.distributions.geometric.Geometric(geometric_param).sample_n(inner_batch_size).type(torch.LongTensor).to('cuda')\n","    select_idx_clipped = torch.clamp(select_idx, max=inner_batch_size - 2)\n","    nb_idx = sort_idx_no_itself[torch.arange(inner_batch_size), select_idx_clipped]\n","\n","    # mixup with neighbours #\n","    inputs_nb = inputs[nb_idx]\n","    labels_nb = labels[nb_idx]\n","    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample().to('cuda')\n","    mixup_inputs_nb = lmbda * inputs + (1 - lmbda) * inputs_nb\n","    return mixup_inputs_nb, labels, labels_nb, lmbda"],"id":"tgW61zPwOLn3","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"democratic-smooth","executionInfo":{"status":"ok","timestamp":1625261112709,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n","    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n","    return mixup_loss"],"id":"democratic-smooth","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntv024FgYDzh"},"source":["# Training"],"id":"ntv024FgYDzh"},{"cell_type":"code","metadata":{"id":"adaptive-short","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625262404650,"user_tz":-60,"elapsed":1291944,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"b20ec980-a865-48ed-e988-16e6e7e59bd4"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_mixup_loss = 0.\n","    epoch_loss = 0.\n","    epoch_augment_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","\n","        # Mixup with random neighbour perturbation #\n","        mixup_inputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda = mixup_MNIST_nb(inputs, labels, geometric_param, alpha)\n","        \n","        # Concatenate perturbation and original data, to do augmentation and loss computation #\n","        original_num = inputs.size(0)\n","        augment_inputs = torch.vstack((inputs, mixup_inputs_nb))\n","        augment_outputs = model(augment_inputs)\n","        outputs = augment_outputs[:original_num]\n","        mixup_outputs_nb = augment_outputs[original_num:]\n","        mixup_loss_nb = mixup_criterion(criterion, mixup_outputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda)\n","        loss = criterion(outputs, labels)\n","        weighted_augment_loss = perturb_loss_weight * mixup_loss_nb + (1 - perturb_loss_weight) * loss\n","\n","        # Record #\n","        epoch_mixup_loss += mixup_loss_nb.item()\n","        epoch_loss += loss.item()\n","        epoch_augment_loss += (mixup_loss_nb.item() + loss.item())\n","\n","        # Gradient Calculation & Optimisation #\n","        weighted_augment_loss.backward()\n","        optimizer.step()\n","    \n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print decomposed losses #\n","    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_loss, epoch_augment_loss))"],"id":"adaptive-short","execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:151: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n","  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["0: 207.5427240282297 59.333083032630384 266.8758070608601\n","1: 162.17173591069877 15.5211620493792 177.69289796007797\n","2: 154.52680364251137 8.923135585035197 163.44993922754657\n","3: 146.2786542735994 4.825011096370872 151.10366536997026\n","4: 140.91475942265242 3.3328141855308786 144.2475736081833\n","5: 139.90407819114625 2.4609315060079098 142.36500969715416\n","6: 136.38774933386594 1.4041035769623704 137.7918529108283\n","7: 131.4133437052369 1.2054599421535386 132.61880364739045\n","8: 130.88905187416822 1.0671134571166476 131.95616533128486\n","9: 129.61640408169478 0.8281375741498778 130.44454165584466\n","10: 127.48317166231573 0.6839340334699955 128.16710569578572\n","11: 127.26585679501295 0.6572566887189168 127.92311348373187\n","12: 124.1473149517551 0.7183302271223511 124.86564517887746\n","13: 127.67293124645948 0.6952671352191828 128.36819838167867\n","14: 124.09103498980403 0.5568146784498822 124.64784966825391\n","15: 123.6188977714628 0.49279998255951796 124.11169775402232\n","16: 120.16277981456369 0.506551363512699 120.66933117807639\n","17: 122.68918749410659 0.4706435497646453 123.15983104387124\n","18: 121.95705340150744 0.4206777146246168 122.37773111613205\n","19: 124.037314504385 0.48971657934453106 124.52703108372953\n","20: 118.81254982249811 0.4769525991505361 119.28950242164865\n","21: 119.46467994106933 0.4224854276726546 119.88716536874199\n","22: 119.96866137720644 0.4162608808837831 120.38492225809023\n","23: 118.72130272258073 0.4117366736609256 119.13303939624166\n","24: 119.67995521612465 0.34392607153131394 120.02388128765597\n","25: 118.32738678064197 0.33812092048174236 118.66550770112372\n","26: 120.07057061605155 0.33010709429800045 120.40067771034956\n","27: 117.95501582231373 0.34869073543086415 118.30370655774459\n","28: 115.54472831077874 0.33910626405850053 115.88383457483724\n","29: 118.28984788106754 0.5156712461757706 118.80551912724331\n","30: 116.96682892926037 0.3726320485366159 117.33946097779699\n","31: 115.30397430853918 0.3655798333202256 115.66955414185941\n","32: 116.28283864678815 0.32347290202596923 116.60631154881412\n","33: 113.83212564559653 0.3183696915730252 114.15049533716956\n","34: 116.86042510159314 0.2984965730793192 117.15892167467246\n","35: 114.87118496815674 0.2917145201427047 115.16289948829944\n","36: 117.82500213664025 0.3067293472486199 118.13173148388887\n","37: 115.49802261777222 0.3039610832784092 115.80198370105063\n","38: 114.37323300912976 0.2852212171164865 114.65845422624625\n","39: 117.58539332542568 0.26103426796908025 117.84642759339476\n","40: 113.32001031562686 0.3111356260778848 113.63114594170474\n","41: 115.4937604223378 0.2645562360994518 115.75831665843725\n","42: 113.78732643369585 0.5150290749515989 114.30235550864745\n","43: 113.56207666732371 0.5109985198287177 114.07307518715243\n","44: 109.79297585599124 0.5369212729492574 110.3298971289405\n","45: 115.01834900351241 0.31041508759881253 115.32876409111122\n","46: 110.16243826784194 0.27062470728560584 110.43306297512754\n","47: 113.37140063103288 0.2684624019966577 113.63986303302954\n","48: 111.96399448812008 0.2499466625849891 112.21394115070507\n","49: 113.92399750696495 0.22176869059694582 114.1457661975619\n","50: 107.5359613345936 0.22297919986158377 107.75894053445518\n","51: 113.18045116122812 0.18060270265414147 113.36105386388226\n","52: 108.26843235641718 0.1921157308097463 108.46054808722693\n","53: 107.37055379990488 0.19888019657082623 107.56943399647571\n","54: 110.28221047390252 0.19407562727064942 110.47628610117317\n","55: 109.96673235017806 0.17829322534817038 110.14502557552623\n","56: 109.93225313536823 0.1817786594365316 110.11403179480476\n","57: 106.62528659868985 0.20044304857219686 106.82572964726205\n","58: 108.59428100613877 0.20013508183183149 108.7944160879706\n","59: 104.18520572502166 0.21100666981510585 104.39621239483677\n","60: 109.55811212910339 0.18126513015522505 109.73937725925862\n","61: 104.27258411841467 0.2093236305663595 104.48190774898103\n","62: 109.7041303794831 0.17589887225767598 109.88002925174078\n","63: 106.85749500244856 0.1854518666623335 107.04294686911089\n","64: 105.46452994085848 0.2086088302457938 105.67313877110428\n","65: 109.8740578647703 0.17615363396180328 110.0502114987321\n","66: 108.97556751128286 0.19017686154256808 109.16574437282543\n","67: 108.3475435054861 0.19315804533835035 108.54070155082445\n","68: 108.63088148646057 0.17078132206734153 108.80166280852791\n","69: 107.42634207289666 0.18524088624326396 107.61158295913992\n","70: 107.02020126115531 0.19279941367858555 107.21300067483389\n","71: 108.67997232824564 0.17582279476482654 108.85579512301047\n","72: 108.80568639514968 0.18711738188721938 108.9928037770369\n","73: 105.3507304280065 0.19977075200949912 105.550501180016\n","74: 108.6375576381106 0.18363842015969567 108.82119605827029\n","75: 107.95284544490278 0.18036195653985487 108.13320740144263\n","76: 108.80031395656988 0.17599083862296538 108.97630479519285\n","77: 107.11653010873124 0.18213800747616915 107.29866811620741\n","78: 106.32663440611213 0.1848924547812203 106.51152686089335\n","79: 110.31824521580711 0.1641485463551362 110.48239376216225\n","80: 106.33580049593002 0.2044591895028134 106.54025968543283\n","81: 106.89573821891099 0.18363584791586618 107.07937406682686\n","82: 106.97933996701613 0.1954835584765533 107.17482352549268\n","83: 106.751096367836 0.18813843201860436 106.9392347998546\n","84: 107.86498991865665 0.18152141551036038 108.04651133416701\n","85: 108.09314895560965 0.18260548170655966 108.27575443731621\n","86: 106.29282165830955 0.19657040118181612 106.48939205949137\n","87: 107.71273766085505 0.18492119343864033 107.8976588542937\n","88: 107.25562858674675 0.1755198371647566 107.43114842391151\n","89: 104.54059235472232 0.19290419897879474 104.73349655370112\n","90: 105.5143942865543 0.19489814745247713 105.70929243400678\n","91: 106.92476823180914 0.19245585432145162 107.11722408613059\n","92: 104.71523165656254 0.20082259682021686 104.91605425338275\n","93: 107.75077870627865 0.16959259510986158 107.92037130138851\n","94: 106.43115943484008 0.18603815972892335 106.617197594569\n","95: 105.73958274396136 0.19049299896141747 105.93007574292278\n","96: 106.02264835964888 0.18749980853317538 106.21014816818206\n","97: 107.9783064732328 0.17372689427429577 108.1520333675071\n","98: 108.22341043781489 0.17379751764019602 108.39720795545509\n","99: 106.86464654654264 0.18512479066703236 107.04977133720968\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_X5YE5kBZ5ao"},"source":["# Save model"],"id":"_X5YE5kBZ5ao"},{"cell_type":"code","metadata":{"id":"armed-contact","executionInfo":{"status":"ok","timestamp":1625262404651,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["# torch.save(model.state_dict(), './mixup_model_pytorch_mnist')\n","# model = models.resnet18(pretrained=False)\n","# model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n","# model.fc = torch.nn.Linear(512, 10)\n","# model.load_state_dict(torch.load('./mixup_model_pytorch_mnist'))"],"id":"armed-contact","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KI0HoDg3Z7sX"},"source":["# Test on Test Data"],"id":"KI0HoDg3Z7sX"},{"cell_type":"code","metadata":{"id":"competitive-penny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625262406224,"user_tz":-60,"elapsed":1579,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"abd0c46b-d493-427f-be5f-5336031b94f9"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"competitive-penny","execution_count":11,"outputs":[{"output_type":"stream","text":["0.994\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4VE_ydjNZ-RY"},"source":["# Test on Train Data"],"id":"4VE_ydjNZ-RY"},{"cell_type":"code","metadata":{"id":"victorian-financing","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625262415539,"user_tz":-60,"elapsed":9319,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"aec0012e-5d74-40b9-9684-620849afea35"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"victorian-financing","execution_count":12,"outputs":[{"output_type":"stream","text":["1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"capital-situation","executionInfo":{"status":"ok","timestamp":1625262415539,"user_tz":-60,"elapsed":13,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":[""],"id":"capital-situation","execution_count":12,"outputs":[]}]}