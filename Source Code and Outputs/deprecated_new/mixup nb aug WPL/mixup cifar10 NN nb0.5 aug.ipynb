{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"mixup cifar10 NN nb0.5 aug.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_b2Nvqg3Oifz"},"source":["# Import Libraries"],"id":"_b2Nvqg3Oifz"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"romantic-purchase","executionInfo":{"status":"ok","timestamp":1625316843312,"user_tz":-60,"elapsed":983,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"f8332b66-c882-4b62-dfd0-ce3f36033fde"},"source":["import torch\n","from torchvision import transforms, datasets\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"romantic-purchase","execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qiPvZSTKO0Pk"},"source":["# Import outside code"],"id":"qiPvZSTKO0Pk"},{"cell_type":"code","metadata":{"id":"kw0NscKvO2bI","executionInfo":{"status":"ok","timestamp":1625316843708,"user_tz":-60,"elapsed":397,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["import numpy as np\n","from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_circles, make_classification, make_regression\n","\n","\n","def train_val_test_split(data, labels, split=(0.6, 0.2, 0.2)):\n","    # Split data #\n","    num_data = data.shape[0]\n","    num_train_data = int(num_data * split[0])\n","    num_val_data = int(num_data * split[1])\n","    train_data = data[:num_train_data]\n","    train_labels = labels[:num_train_data]\n","    val_data = data[num_train_data:num_train_data + num_val_data]\n","    val_labels = labels[num_train_data:num_train_data + num_val_data]\n","    test_data = data[num_train_data + num_val_data:]\n","    test_labels = labels[num_train_data + num_val_data:]\n","    train_val_test = (train_data, train_labels, val_data, val_labels, test_data, test_labels)\n","    return train_val_test\n","\n","\n","def load_skl_data(data_name, need_num=None, split=(0.6, 0.2, 0.2)):\n","    # Load and unpack data from sklearn & randomise #\n","    if data_name == 'iris':\n","        skl_data = load_iris()\n","    elif data_name == 'wine':\n","        skl_data = load_wine()\n","    elif data_name == 'breast_cancer':\n","        skl_data = load_breast_cancer()\n","    num_data = skl_data['data'].shape[0]\n","    random_idx = np.random.permutation(num_data)\n","    data = skl_data['data'][random_idx]\n","    labels = skl_data['target'][random_idx]\n","\n","    # Require number of data #\n","    if need_num is not None:\n","        data = data[:need_num]\n","        labels = data[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_circular_data(need_num, noise=0.1, factor=0.5, split=(0.6, 0.2, 0.2)):\n","    # Load circular data #\n","    data, labels = make_circles(n_samples=need_num, noise=noise, factor=factor)\n","    labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_two_spirals(need_num, noise=0.5, split=(0.6, 0.2, 0.2)):\n","    # Create two spirals data #\n","    n = np.sqrt(np.random.rand(need_num, 1)) * 780 * (2 * np.pi) / 360\n","    d1x = -np.cos(n) * n + np.random.rand(need_num, 1) * noise\n","    d1y = np.sin(n) * n + np.random.rand(need_num, 1) * noise\n","    data_extended = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y))))\n","    labels_extended = np.hstack((np.ones(need_num) * -1, np.ones(need_num)))\n","    idx = np.random.permutation(need_num * 2)\n","    data_extended = data_extended[idx]\n","    labels_extended = labels_extended[idx]\n","    data = data_extended[:need_num]\n","    labels = labels_extended[:need_num]\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_classification_dataset(need_num, need_features, need_classes=2, need_flip=0.01, class_sep=1.0, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for classification #\n","    n_informative = need_classes\n","    n_redundant = 0\n","    n_repeated = 0\n","    n_cluster_per_class = 2\n","    data, labels = make_classification(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_redundant=n_redundant, n_repeated=n_repeated, n_classes=need_classes, n_clusters_per_class=n_cluster_per_class, flip_y=need_flip, class_sep=class_sep, random_state=random_state)\n","\n","    # Change labels to +1/-1 if it is binary classification #\n","    if need_classes == 2:\n","        labels[labels == 0] = -1\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test\n","\n","\n","def load_random_regression_dataset(need_num, need_features, bias, noise=1, random_state=None, split=(0.6, 0.2, 0.2)):\n","    # Create data for regression #\n","    n_informative = need_features\n","    n_targets = 1\n","    data, labels = make_regression(n_samples=need_num, n_features=need_features, n_informative=n_informative, n_targets=n_targets, bias=bias, noise=noise, random_state=random_state)\n","\n","    # Split data #\n","    train_val_test = train_val_test_split(data, labels, split=split)\n","    return train_val_test"],"id":"kw0NscKvO2bI","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMYYosNOO2V3","executionInfo":{"status":"ok","timestamp":1625316844235,"user_tz":-60,"elapsed":529,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["'''ResNet in PyTorch.\n","\n","BasicBlock and Bottleneck module is from the original ResNet paper:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","\n","PreActBlock and PreActBottleneck module is from the later paper:\n","[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.autograd import Variable\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBlock(nn.Module):\n","    '''Pre-activation version of the BasicBlock.'''\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class PreActBottleneck(nn.Module):\n","    '''Pre-activation version of the original Bottleneck module.'''\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(PreActBottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(x))\n","        shortcut = self.shortcut(out)\n","        out = self.conv1(out)\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = self.conv3(F.relu(self.bn3(out)))\n","        out += shortcut\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, lin=0, lout=5):\n","        out = x\n","        if lin < 1 and lout > -1:\n","            out = self.conv1(out)\n","            out = self.bn1(out)\n","            out = F.relu(out)\n","        if lin < 2 and lout > 0:\n","            out = self.layer1(out)\n","        if lin < 3 and lout > 1:\n","            out = self.layer2(out)\n","        if lin < 4 and lout > 2:\n","            out = self.layer3(out)\n","        if lin < 5 and lout > 3:\n","            out = self.layer4(out)\n","        if lout > 4:\n","            out = F.avg_pool2d(out, 4)\n","            out = out.view(out.size(0), -1)\n","            out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(PreActBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test()\n"],"id":"sMYYosNOO2V3","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pg95DAmvO8un"},"source":["# Configuration"],"id":"pg95DAmvO8un"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"silver-clear","executionInfo":{"status":"ok","timestamp":1625316844235,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"a2a780f1-cd6b-43bc-a609-2b91b8dc20d1"},"source":["\"\"\"\n","Configuration and Hyperparameters\n","\"\"\"\n","#torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU, in pytorch 1.9 even need dataloader to be in GPU\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),  # can omit\n","    transforms.RandomHorizontalFlip(),  # can omit\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        (0.4914, 0.4822, 0.4465),\n","        (0.2023, 0.1994, 0.2010)\n","    )\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        (0.4914, 0.4822, 0.4465),\n","        (0.2023, 0.1994, 0.2010)\n","    )\n","])\n","\n","batch_size = 128\n","step_size = 0.1\n","random_seed = 0\n","epochs = 200\n","L2_decay = 1e-4\n","alpha = 1.\n","geometric_param = 0.5\n","\n","torch.manual_seed(random_seed)"],"id":"silver-clear","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f51b48a2bb0>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"uDMInb7zPT3v"},"source":["# Data"],"id":"uDMInb7zPT3v"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"relative-mobility","executionInfo":{"status":"ok","timestamp":1625316846850,"user_tz":-60,"elapsed":2616,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"dce3df07-d016-4b48-f1a9-5caa3c7a55db"},"source":["\"\"\"\n","Data\n","\"\"\"\n","train_set = datasets.CIFAR10(root='/content/gdrive/My Drive/colab', train=True, download=True, transform=transform_train)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","test_set = datasets.CIFAR10(root='/content/gdrive/My Drive/colab', train=False, download=True, transform=transform_test)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"],"id":"relative-mobility","execution_count":5,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0-R2uhkAPjkv"},"source":["# Models, Loss, Optimiser"],"id":"0-R2uhkAPjkv"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"starting-chancellor","executionInfo":{"status":"ok","timestamp":1625316849110,"user_tz":-60,"elapsed":2261,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"772c70aa-f71f-47a0-fd1d-a83fd2966877"},"source":["model = ResNet18()\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)\n","step_size_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs / 2)], gamma=0.1)\n","model.cuda()"],"id":"starting-chancellor","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layer1): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): PreActBlock(\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      )\n","    )\n","    (1): PreActBlock(\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (linear): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"1qFqkwNmQgeO"},"source":["# Data Augmentation / Perturbation AND corresponding loss"],"id":"1qFqkwNmQgeO"},{"cell_type":"code","metadata":{"id":"contemporary-gross","executionInfo":{"status":"ok","timestamp":1625316849111,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_cifar10_nb(inputs, labels, geometric_param, alpha):\n","    inner_batch_size = labels.size(0)\n","    inputs_flatten = inputs.reshape(inner_batch_size, -1)\n","\n","    # Compute pair-wise distances & sort the distances #\n","    dists = torch.cdist(inputs_flatten, inputs_flatten)\n","    sort_idx = torch.argsort(dists, dim=1)\n","    sort_idx_no_itself = sort_idx[:, 1:]\n","\n","    # Generate geometric random variables for selecting neighbours & get the index of selected neighbour data #\n","    select_idx = torch.distributions.geometric.Geometric(geometric_param).sample_n(inner_batch_size).type(torch.LongTensor).to('cuda')\n","    select_idx_clipped = torch.clamp(select_idx, max=inner_batch_size - 2)\n","    nb_idx = sort_idx_no_itself[torch.arange(inner_batch_size), select_idx_clipped]\n","\n","    # mixup with neighbours #\n","    inputs_nb = inputs[nb_idx]\n","    labels_nb = labels[nb_idx]\n","    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample().to('cuda')\n","    mixup_inputs_nb = lmbda * inputs + (1 - lmbda) * inputs_nb\n","    return mixup_inputs_nb, labels, labels_nb, lmbda"],"id":"contemporary-gross","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"right-spending","executionInfo":{"status":"ok","timestamp":1625316849111,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n","    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n","    return mixup_loss"],"id":"right-spending","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlGDo8vIQoZk"},"source":["# Training"],"id":"TlGDo8vIQoZk"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"written-bookmark","executionInfo":{"status":"ok","timestamp":1625326682467,"user_tz":-60,"elapsed":9833358,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"7daae04b-014f-4e00-88fc-dc969265a269"},"source":["\"\"\"\n","Training\n","\"\"\"\n","model.train()\n","for epoch in range(epochs):\n","    epoch_mixup_loss = 0.\n","    epoch_loss = 0.\n","    epoch_augment_loss = 0.\n","    for i, data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","\n","        # Mixup with random neighbour perturbation #\n","        mixup_inputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda = mixup_cifar10_nb(inputs, labels, geometric_param, alpha)\n","        \n","        # Concatenate perturbation and original data, to do augmentation and loss computation #\n","        original_num = inputs.size(0)\n","        augment_inputs = torch.vstack((inputs, mixup_inputs_nb))\n","        augment_outputs = model(augment_inputs)\n","        outputs = augment_outputs[:original_num]\n","        mixup_outputs_nb = augment_outputs[original_num:]\n","        mixup_loss_nb = mixup_criterion(criterion, mixup_outputs_nb, mixup_labels_nb_a, mixup_labels_nb_b, lmbda)\n","        loss = criterion(outputs, labels)\n","        augment_loss = mixup_loss_nb + loss\n","        \n","        # Record #\n","        epoch_mixup_loss += mixup_loss_nb.item()\n","        epoch_loss += loss.item()\n","        epoch_augment_loss += augment_loss.item()\n","\n","        # Gradient Calculation & Optimisation #\n","        augment_loss.backward()\n","        optimizer.step()\n","    \n","    # Step size scheduler #\n","    step_size_scheduler.step()\n","    \n","    # Print decomposed losses #\n","    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_loss, epoch_augment_loss))"],"id":"written-bookmark","execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:151: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n","  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["0: 899.7931730747223 1149.8252737522125 2049.6184508800507\n","1: 807.3000165224075 792.8292262554169 1600.1292476654053\n","2: 797.1493126153946 772.619192481041 1569.7685053348541\n","3: 782.6757398843765 743.3935364484787 1526.069272518158\n","4: 761.0242693424225 708.3517879247665 1469.3760588169098\n","5: 735.1910312175751 668.728546500206 1403.9195773601532\n","6: 713.7342102527618 631.2704975605011 1345.0047073364258\n","7: 698.8857700824738 599.0224286317825 1297.9081993103027\n","8: 687.1293632984161 573.4170036315918 1260.5463705062866\n","9: 672.2216989994049 551.6930896043777 1223.9147884845734\n","10: 661.939713716507 524.056903719902 1185.996616601944\n","11: 652.5637594461441 497.7533007860184 1150.317061662674\n","12: 624.7639126777649 470.51477670669556 1095.278687953949\n","13: 621.2471581101418 439.7329449057579 1060.9801020622253\n","14: 606.2402074337006 410.5391928553581 1016.7793974876404\n","15: 591.5112155675888 383.5874235033989 975.0986400842667\n","16: 569.3217857480049 356.28232049942017 925.6041045188904\n","17: 554.1346640586853 329.8078737258911 883.9425365924835\n","18: 554.7918331027031 309.033104121685 863.8249351978302\n","19: 546.9122225046158 289.3218812942505 836.2341043949127\n","20: 524.2425299286842 272.0760198533535 796.318550825119\n","21: 525.860261619091 255.72935336828232 781.5896158218384\n","22: 518.9495595991611 245.66457387804985 764.6141331195831\n","23: 520.0149505734444 233.09750133752823 753.1124522686005\n","24: 504.0239842236042 222.42872005701065 726.4527049064636\n","25: 497.87599182128906 212.5635658800602 710.4395572543144\n","26: 499.18926241993904 208.1854109764099 707.374673306942\n","27: 495.21527817845345 197.49936097860336 692.7146387696266\n","28: 487.7963640987873 191.31713378429413 679.1134999394417\n","29: 481.1288649737835 186.24080723524094 667.3696731328964\n","30: 481.63999712467194 177.35739293694496 658.9973905086517\n","31: 468.941958963871 172.71028411388397 641.6522421836853\n","32: 462.8668147623539 167.25454863905907 630.1213622689247\n","33: 479.4055155515671 161.0791874229908 640.4847019910812\n","34: 465.2928301990032 156.649776622653 621.9426073431969\n","35: 460.88143187761307 152.30972327291965 613.1911563277245\n","36: 458.49339932203293 147.9413846731186 606.4347848296165\n","37: 455.10598960518837 142.6610858887434 597.7670761346817\n","38: 461.1625605523586 138.04396583139896 599.2065253853798\n","39: 434.59433150291443 136.77080304920673 571.3651348948479\n","40: 451.3535090982914 132.8097206801176 584.1632310152054\n","41: 450.73716163635254 126.77017252147198 577.5073350071907\n","42: 440.37201008200645 124.00002935528755 564.3720396161079\n","43: 449.98291581869125 118.43826119601727 568.4211766719818\n","44: 450.54336753487587 114.75454975664616 565.297917664051\n","45: 442.1886864602566 113.19856594502926 555.3872528076172\n","46: 431.8938482403755 111.06267729401588 542.9565257132053\n","47: 432.4598815590143 106.86282148957253 539.322702974081\n","48: 437.49211896955967 104.0854222625494 541.5775412023067\n","49: 428.91146244108677 102.84838293492794 531.7598456442356\n","50: 433.7528631836176 99.05509130656719 532.8079558312893\n","51: 428.4062872827053 97.15074104070663 525.5570290386677\n","52: 418.31878577172756 95.12144491821527 513.4402310550213\n","53: 420.6680402010679 93.89803076535463 514.5660716593266\n","54: 421.9044296145439 90.01584554463625 511.9202746450901\n","55: 419.9885822683573 87.88632073998451 507.87490417063236\n","56: 424.17894861102104 85.46435581892729 509.64330503344536\n","57: 412.8084096610546 82.41001815348864 495.21842908859253\n","58: 409.09891530126333 83.20751924067736 492.30643409490585\n","59: 427.7629664093256 80.48920770734549 508.2521752715111\n","60: 421.8066247329116 77.91131316870451 499.7179376780987\n","61: 402.54089392721653 79.20316430181265 481.7440588772297\n","62: 417.62098786234856 77.41934384405613 495.0403307378292\n","63: 417.02791237831116 74.54979145526886 491.57770428061485\n","64: 401.8625146225095 72.6822577342391 474.54477021098137\n","65: 398.4586388617754 71.47640439122915 469.9350433051586\n","66: 406.961165368557 70.73147609084845 477.6926421523094\n","67: 404.277051910758 71.98401252925396 476.26106452941895\n","68: 410.05083191394806 67.29893376678228 477.34976613521576\n","69: 409.97592240571976 69.2459259480238 479.2218479812145\n","70: 395.64319675415754 68.75852083414793 464.40171767771244\n","71: 410.474796846509 62.9855249710381 473.46032068133354\n","72: 402.82828145474195 66.37163703888655 469.19991832971573\n","73: 402.03468396514654 64.13059978932142 466.16528367996216\n","74: 412.29490104317665 63.90046964585781 476.1953703761101\n","75: 396.72050170600414 59.25952458381653 455.9800270497799\n","76: 379.4064225330949 62.39998745918274 441.8064104169607\n","77: 400.0611980780959 58.53889023885131 458.6000895947218\n","78: 391.1572995111346 60.73290325701237 451.8902034461498\n","79: 397.9252030476928 57.974018298089504 455.8992217183113\n","80: 398.7830314338207 59.12276300787926 457.9057941734791\n","81: 393.8484694212675 60.79852608591318 454.646995306015\n","82: 399.0515073686838 55.1598107740283 454.211319193244\n","83: 394.7627697661519 57.52334016561508 452.2861103117466\n","84: 400.75579315423965 57.604770608246326 458.3605637550354\n","85: 393.2911176234484 56.42738952115178 449.71850740909576\n","86: 396.94049287587404 52.14374816790223 449.0842415988445\n","87: 392.56353118270636 56.49640565738082 449.05993673205376\n","88: 412.1102862358093 52.072929967194796 464.1832153648138\n","89: 404.6642858684063 51.0244399830699 455.6887257993221\n","90: 401.85149796307087 54.48224079981446 456.3337388038635\n","91: 388.8844959512353 52.22877809777856 441.11327393352985\n","92: 401.33828787505627 53.01551518216729 454.3538033813238\n","93: 383.3924906998873 51.12258433923125 434.51507541537285\n","94: 392.869268886745 52.064742632210255 444.9340115636587\n","95: 386.4789024218917 54.04840785264969 440.52731098234653\n","96: 389.64928844571114 51.74320165067911 441.39248901605606\n","97: 390.8192791044712 49.666731383651495 440.48601028323174\n","98: 386.4876281917095 49.43939667567611 435.9270246475935\n","99: 388.4394923001528 48.79175420105457 437.2312461733818\n","100: 368.0782200396061 25.988712733611465 394.06693305820227\n","101: 365.55237386003137 17.971175603568554 383.5235498175025\n","102: 358.8791071623564 15.340754658915102 374.2198616191745\n","103: 354.55625162646174 13.613712806254625 368.16996498405933\n","104: 340.2509751878679 13.08185985404998 353.33283518627286\n","105: 350.02599190734327 12.165786293335259 362.1917786039412\n","106: 339.1652006153017 11.245650579221547 350.41085051745176\n","107: 341.9553755633533 11.160399998538196 353.11577462404966\n","108: 352.1531396917999 10.33801352698356 362.4911526814103\n","109: 338.2182607538998 10.12271917425096 348.34098045900464\n","110: 329.4658491127193 9.496636329218745 338.9624855518341\n","111: 332.17501252517104 9.37515028938651 341.55016293004155\n","112: 354.9488190449774 9.209581917151809 364.1584010235965\n","113: 340.48794458061457 9.123405280523002 349.61134910583496\n","114: 345.0526513159275 8.81073182914406 353.86338276416063\n","115: 345.4248360991478 8.479535590857267 353.9043722897768\n","116: 336.5873558651656 8.534801181405783 345.12215684726834\n","117: 339.33839272893965 8.048113698139787 347.3865053318441\n","118: 325.49083722010255 8.25984208052978 333.75067944452167\n","119: 334.4085152298212 8.397583570331335 342.806098587811\n","120: 339.3227133974433 8.131911813281476 347.4546250067651\n","121: 324.424907784909 7.7869035438634455 332.2118115648627\n","122: 336.15029608272016 7.550582188181579 343.70087791606784\n","123: 326.43485760875046 7.362518875859678 333.79737593233585\n","124: 331.06877649202943 7.733486883342266 338.80226323381066\n","125: 336.04903681203723 7.592264330945909 343.64130073040724\n","126: 332.1173453051597 7.550154444295913 339.6674997061491\n","127: 327.3731078580022 7.51867154892534 334.8917794022709\n","128: 327.9217988718301 7.197141298092902 335.11894042417407\n","129: 339.7696762830019 6.667790315113962 346.4374667145312\n","130: 335.6705828215927 6.965363709721714 342.635947663337\n","131: 326.137708212249 7.122240140568465 333.2599495239556\n","132: 344.5279440432787 6.9466180531308055 351.4745619148016\n","133: 334.7093878611922 6.952852608636022 341.66224029660225\n","134: 334.2161904871464 6.8571004224941134 341.07329017296433\n","135: 329.09059314616024 6.796793408691883 335.8873864002526\n","136: 326.29989083111286 6.930591487325728 333.2304828502238\n","137: 332.94652761146426 6.678529942873865 339.62505713291466\n","138: 321.6569419708103 6.789306685328484 328.4462488498539\n","139: 327.4461362157017 6.322594431228936 333.76873041689396\n","140: 337.2164286142215 6.670545468572527 343.88697450235486\n","141: 326.4457277879119 6.536087564658374 332.9818164743483\n","142: 335.11159171536565 6.429445750080049 341.5410369411111\n","143: 329.9792722277343 6.34169635316357 336.32096917554736\n","144: 338.87167350389063 6.175121074076742 345.04679475724697\n","145: 318.56601681001484 6.2422058074735105 324.8082232363522\n","146: 334.6071561537683 6.084007903933525 340.691164445132\n","147: 320.34795665740967 6.267492400482297 326.6154497079551\n","148: 325.01753553934395 6.328894817736 331.3464308157563\n","149: 331.57678854092956 6.177049657795578 337.75383807718754\n","150: 323.7183068655431 6.330100101418793 330.048407189548\n","151: 336.81483423151076 6.055759878829122 342.8705940693617\n","152: 334.31399393081665 6.235405493993312 340.549399740994\n","153: 335.909825976938 6.3662347975187 342.27606074512005\n","154: 320.53064335510135 6.141453163698316 326.6720962487161\n","155: 335.2899381890893 5.920436387881637 341.2103745378554\n","156: 321.12774101644754 5.887769252061844 327.01550951600075\n","157: 319.627500904724 6.197955120820552 325.8254557698965\n","158: 335.3050930015743 5.93079084251076 341.23588389344513\n","159: 325.5536762215197 5.988104695919901 331.5417810678482\n","160: 328.7348896674812 6.0461028828285635 334.78099239990115\n","161: 317.6890650559217 5.9445741339586675 323.6336384899914\n","162: 315.57544320076704 5.877947031520307 321.4533908031881\n","163: 327.2131323516369 5.8951857928186655 333.1083178706467\n","164: 323.56379286572337 5.74538479745388 329.30917809158564\n","165: 329.6370524764061 5.845197530463338 335.48225075379014\n","166: 325.6730964090675 5.75976002542302 331.43285601213574\n","167: 328.11435165442526 5.864671149291098 333.9790222607553\n","168: 324.05198336951435 5.715141840744764 329.7671246305108\n","169: 310.90132508799434 5.788019130937755 316.68934416770935\n","170: 320.4423427544534 5.767161968629807 326.20950527861714\n","171: 323.54969845712185 5.885816443711519 329.43551499024034\n","172: 331.95692763477564 5.738508173730224 337.6954362206161\n","173: 332.729938948527 5.488209949806333 338.2181491404772\n","174: 319.7377032060176 5.763971459120512 325.5016746520996\n","175: 331.474877782166 5.630779444705695 337.1056576371193\n","176: 322.65658585727215 5.574928552377969 328.23151461035013\n","177: 331.4958249516785 5.579496079590172 337.0753219500184\n","178: 313.2046221792698 5.529191893525422 318.73381331562996\n","179: 311.05705141089857 5.883210371248424 316.94026180543005\n","180: 324.57637668028474 5.642519221175462 330.2188963778317\n","181: 320.5400416068733 5.816322731785476 326.35636372864246\n","182: 317.6705789063126 5.430892281234264 323.10147063806653\n","183: 319.6611631065607 5.460731476079673 325.1218943595886\n","184: 312.6651817560196 5.5101024699397385 318.17528519779444\n","185: 313.55231442674994 5.770839580800384 319.3231546357274\n","186: 313.6118815690279 5.571745382156223 319.1836270019412\n","187: 316.7160953320563 5.456655585672706 322.17275132611394\n","188: 322.7999066747725 5.344742128159851 328.14464839175344\n","189: 323.2718994691968 5.476924003101885 328.748824223876\n","190: 304.3544520046562 5.368205344770104 309.7226564064622\n","191: 313.7958859242499 5.585018843412399 319.3809046931565\n","192: 324.2606295738369 5.378626799676567 329.6392554678023\n","193: 320.7501958049834 5.4503921451978385 326.2005878314376\n","194: 319.26732310280204 5.483674061018974 324.7509974054992\n","195: 325.3375991489738 5.424759889487177 330.7623589448631\n","196: 308.88219286873937 5.675373831298202 314.55756613612175\n","197: 328.15572629868984 5.455858036177233 333.6115838289261\n","198: 324.91215098276734 5.354606930166483 330.26675805449486\n","199: 315.6385125052184 5.631356301251799 321.26986886560917\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"doR5kS81SW5F"},"source":["# Save model"],"id":"doR5kS81SW5F"},{"cell_type":"code","metadata":{"id":"frozen-damage","executionInfo":{"status":"ok","timestamp":1625326682468,"user_tz":-60,"elapsed":8,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":["# torch.save(model.state_dict(), './mixup_model_pytorch_cifar10')\n","# model = models.__dict__['ResNet18']()\n","# model.load_state_dict(torch.load('./mixup_model_pytorch_cifar10'))"],"id":"frozen-damage","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLlLnmpRSZAl"},"source":["# Test on Test Data"],"id":"BLlLnmpRSZAl"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aboriginal-lafayette","executionInfo":{"status":"ok","timestamp":1625326685778,"user_tz":-60,"elapsed":3315,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"34914465-6157-4352-a55b-040aa4385d6b"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"aboriginal-lafayette","execution_count":11,"outputs":[{"output_type":"stream","text":["0.9435\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xHj0XxoMScbg"},"source":["# Test on Train Data"],"id":"xHj0XxoMScbg"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"therapeutic-orlando","executionInfo":{"status":"ok","timestamp":1625326706931,"user_tz":-60,"elapsed":21155,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}},"outputId":"6b0783bc-6063-48ff-99f9-b25f4db0ef89"},"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        outputs = model(inputs)\n","        _, predicts = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicts == labels).sum().item()\n","print(correct / total)"],"id":"therapeutic-orlando","execution_count":12,"outputs":[{"output_type":"stream","text":["0.99982\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XCvQUWwMSetI","executionInfo":{"status":"ok","timestamp":1625326706932,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniel H. Leung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXCFzebYz1uGv2ihM6hqeswMrHPmHtZOloQpE_0A=s64","userId":"09200240480627929504"}}},"source":[""],"id":"XCvQUWwMSetI","execution_count":12,"outputs":[]}]}