{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proprietary-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from load_data import load_skl_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silent-johns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fa6912f470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.005\n",
    "random_seed = 0\n",
    "epochs = 300\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_skl_data('breast_cancer')\n",
    "test_data = np.vstack((val_data, test_data))\n",
    "test_labels = np.hstack((val_labels, test_labels))\n",
    "train_data = torch.from_numpy(train_data).type(torch.FloatTensor)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "test_data = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "train_mean = torch.mean(train_data, 0)\n",
    "train_std = torch.std(train_data, 0)\n",
    "train_data = (train_data - train_mean) / train_std\n",
    "test_data = (test_data - train_mean) / train_std\n",
    "train_set = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "test_set = torch.utils.data.TensorDataset(test_data, test_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "buried-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_model(\n",
      "  (fc1): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class fc_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fc_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "    def forward(self, inputs):\n",
    "        fc1_out = F.tanh(self.fc1(inputs))\n",
    "        fc2_out = F.tanh(self.fc2(fc1_out))\n",
    "        fc3_out = F.tanh(self.fc3(fc2_out))\n",
    "        fc4_out = self.fc4(fc3_out)\n",
    "        return fc4_out\n",
    "\n",
    "model = fc_model()\n",
    "print(model)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quiet-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_breast(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opening-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pediatric-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\Python3_8\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.0461989641189575\n",
      "1: 2.0237956047058105\n",
      "2: 2.0033912658691406\n",
      "3: 1.9420399069786072\n",
      "4: 1.9133285880088806\n",
      "5: 1.8717233538627625\n",
      "6: 1.8323240280151367\n",
      "7: 1.7340384721755981\n",
      "8: 1.7421727180480957\n",
      "9: 1.6723023056983948\n",
      "10: 1.6076797246932983\n",
      "11: 1.594018131494522\n",
      "12: 1.535119354724884\n",
      "13: 1.4752327501773834\n",
      "14: 1.4113210439682007\n",
      "15: 1.391959697008133\n",
      "16: 1.4482013881206512\n",
      "17: 1.319275140762329\n",
      "18: 1.3137077689170837\n",
      "19: 1.3446776568889618\n",
      "20: 1.1584212183952332\n",
      "21: 1.2139899134635925\n",
      "22: 1.140759900212288\n",
      "23: 1.2624471187591553\n",
      "24: 1.0225567817687988\n",
      "25: 1.0902754664421082\n",
      "26: 1.1743187010288239\n",
      "27: 1.2302490770816803\n",
      "28: 1.2026764452457428\n",
      "29: 1.1247140616178513\n",
      "30: 1.1421386301517487\n",
      "31: 1.2494148910045624\n",
      "32: 0.873277947306633\n",
      "33: 1.2062069475650787\n",
      "34: 1.164337232708931\n",
      "35: 0.8178000450134277\n",
      "36: 1.1756654679775238\n",
      "37: 1.3299857676029205\n",
      "38: 1.1501910984516144\n",
      "39: 1.3481009304523468\n",
      "40: 1.1710408926010132\n",
      "41: 1.3687077760696411\n",
      "42: 1.027074173092842\n",
      "43: 1.1828822791576385\n",
      "44: 1.2204920053482056\n",
      "45: 1.0948069095611572\n",
      "46: 1.2531541883945465\n",
      "47: 0.7793920487165451\n",
      "48: 1.1856303811073303\n",
      "49: 0.8457767814397812\n",
      "50: 1.1359913349151611\n",
      "51: 1.2988283038139343\n",
      "52: 1.1404421925544739\n",
      "53: 1.1747145056724548\n",
      "54: 0.9285957366228104\n",
      "55: 0.9576399773359299\n",
      "56: 1.221584141254425\n",
      "57: 1.1091767847537994\n",
      "58: 0.7418641149997711\n",
      "59: 1.4207632541656494\n",
      "60: 1.1524553000926971\n",
      "61: 1.129540130496025\n",
      "62: 1.199809193611145\n",
      "63: 1.2452370822429657\n",
      "64: 0.9519166052341461\n",
      "65: 1.2384640872478485\n",
      "66: 1.046441525220871\n",
      "67: 1.1974537372589111\n",
      "68: 1.1349224746227264\n",
      "69: 1.290903240442276\n",
      "70: 1.2849178910255432\n",
      "71: 1.353419154882431\n",
      "72: 1.2737030386924744\n",
      "73: 0.7260704189538956\n",
      "74: 1.2014046013355255\n",
      "75: 1.3738067746162415\n",
      "76: 1.1204753667116165\n",
      "77: 0.9763876497745514\n",
      "78: 1.2526779472827911\n",
      "79: 1.0182079374790192\n",
      "80: 1.231298714876175\n",
      "81: 1.2621247470378876\n",
      "82: 1.0020691454410553\n",
      "83: 1.348574697971344\n",
      "84: 1.1958850622177124\n",
      "85: 1.1722572147846222\n",
      "86: 1.2265633344650269\n",
      "87: 1.2982841730117798\n",
      "88: 1.0384511500597\n",
      "89: 0.9937117397785187\n",
      "90: 0.8092174232006073\n",
      "91: 0.8654160797595978\n",
      "92: 0.8890749216079712\n",
      "93: 1.1208862364292145\n",
      "94: 1.0151066780090332\n",
      "95: 1.2544707655906677\n",
      "96: 0.9915915727615356\n",
      "97: 1.1520274877548218\n",
      "98: 1.113816887140274\n",
      "99: 0.7253801971673965\n",
      "100: 0.7885333150625229\n",
      "101: 1.0152963548898697\n",
      "102: 1.2658703923225403\n",
      "103: 1.0028623640537262\n",
      "104: 0.8244715481996536\n",
      "105: 1.358078420162201\n",
      "106: 1.357139229774475\n",
      "107: 0.8575164526700974\n",
      "108: 1.1562139093875885\n",
      "109: 1.2586168050765991\n",
      "110: 0.7231935560703278\n",
      "111: 1.3209719061851501\n",
      "112: 0.9667880237102509\n",
      "113: 1.088422417640686\n",
      "114: 0.9106834977865219\n",
      "115: 1.071482390165329\n",
      "116: 1.3602096438407898\n",
      "117: 1.1099957823753357\n",
      "118: 1.25518000125885\n",
      "119: 1.0705716609954834\n",
      "120: 1.35885751247406\n",
      "121: 1.2494399845600128\n",
      "122: 1.2129625976085663\n",
      "123: 1.1572141200304031\n",
      "124: 0.7205518037080765\n",
      "125: 1.1268720030784607\n",
      "126: 1.1507290601730347\n",
      "127: 1.1507439315319061\n",
      "128: 1.0646920204162598\n",
      "129: 1.0310703217983246\n",
      "130: 1.1422136723995209\n",
      "131: 1.0733759999275208\n",
      "132: 1.2009259760379791\n",
      "133: 0.8578643947839737\n",
      "134: 0.9420647025108337\n",
      "135: 1.13816499710083\n",
      "136: 1.0301549434661865\n",
      "137: 1.262644112110138\n",
      "138: 1.1639915108680725\n",
      "139: 1.0910956263542175\n",
      "140: 0.9610002636909485\n",
      "141: 1.2124858498573303\n",
      "142: 1.039955347776413\n",
      "143: 1.0191380381584167\n",
      "144: 0.9173110723495483\n",
      "145: 1.0989574790000916\n",
      "146: 0.866285115480423\n",
      "147: 1.0174256563186646\n",
      "148: 0.9148571193218231\n",
      "149: 0.9181738644838333\n",
      "150: 0.9651109874248505\n",
      "151: 1.1729817688465118\n",
      "152: 1.1582574844360352\n",
      "153: 1.0324277132749557\n",
      "154: 0.847243458032608\n",
      "155: 0.9723707735538483\n",
      "156: 0.9678202420473099\n",
      "157: 0.9931698441505432\n",
      "158: 1.0216570496559143\n",
      "159: 1.257506251335144\n",
      "160: 0.7650844752788544\n",
      "161: 1.046973392367363\n",
      "162: 0.7488903999328613\n",
      "163: 0.523980125784874\n",
      "164: 1.1549503803253174\n",
      "165: 1.010160580277443\n",
      "166: 1.0555275678634644\n",
      "167: 1.011247843503952\n",
      "168: 0.8077101558446884\n",
      "169: 1.0099058896303177\n",
      "170: 1.033286690711975\n",
      "171: 1.2583999633789062\n",
      "172: 1.1854149997234344\n",
      "173: 1.0279993414878845\n",
      "174: 1.230663150548935\n",
      "175: 1.1300455629825592\n",
      "176: 1.2415252029895782\n",
      "177: 0.6254794895648956\n",
      "178: 1.1715901792049408\n",
      "179: 0.833388939499855\n",
      "180: 1.0765042304992676\n",
      "181: 1.0670420825481415\n",
      "182: 1.0140357911586761\n",
      "183: 1.19174063205719\n",
      "184: 0.8942996263504028\n",
      "185: 1.2535298764705658\n",
      "186: 1.1844131648540497\n",
      "187: 1.0579036474227905\n",
      "188: 0.9178504049777985\n",
      "189: 1.394785076379776\n",
      "190: 1.057935193181038\n",
      "191: 1.016295239329338\n",
      "192: 1.1742319166660309\n",
      "193: 1.283201813697815\n",
      "194: 0.8308765143156052\n",
      "195: 0.8624869138002396\n",
      "196: 0.5943594127893448\n",
      "197: 1.2806674242019653\n",
      "198: 1.323542296886444\n",
      "199: 0.9229510426521301\n",
      "200: 1.0564458072185516\n",
      "201: 1.4370248019695282\n",
      "202: 1.0057817697525024\n",
      "203: 1.2661243975162506\n",
      "204: 1.0852197259664536\n",
      "205: 0.7441911995410919\n",
      "206: 0.9710560441017151\n",
      "207: 1.1508108079433441\n",
      "208: 1.0294246077537537\n",
      "209: 0.6490754038095474\n",
      "210: 1.108211189508438\n",
      "211: 0.9244413524866104\n",
      "212: 1.2523247003555298\n",
      "213: 1.1505233645439148\n",
      "214: 0.9268957376480103\n",
      "215: 1.1791667342185974\n",
      "216: 0.7827920913696289\n",
      "217: 0.9734395742416382\n",
      "218: 1.0941390991210938\n",
      "219: 1.2977190017700195\n",
      "220: 1.1661201119422913\n",
      "221: 0.9877040386199951\n",
      "222: 1.0901483297348022\n",
      "223: 0.8602825105190277\n",
      "224: 1.1893161535263062\n",
      "225: 1.2666527926921844\n",
      "226: 1.1476335227489471\n",
      "227: 0.8747159093618393\n",
      "228: 1.1336261928081512\n",
      "229: 1.177001953125\n",
      "230: 1.0960813760757446\n",
      "231: 1.0414572358131409\n",
      "232: 1.1475342214107513\n",
      "233: 0.9320199340581894\n",
      "234: 0.9852395951747894\n",
      "235: 1.0664065778255463\n",
      "236: 1.3020258843898773\n",
      "237: 1.0273312330245972\n",
      "238: 1.3086850047111511\n",
      "239: 1.3115721642971039\n",
      "240: 0.7998911291360855\n",
      "241: 1.0513674318790436\n",
      "242: 1.199272871017456\n",
      "243: 1.0038966238498688\n",
      "244: 1.0327986776828766\n",
      "245: 0.6761457026004791\n",
      "246: 0.8239162415266037\n",
      "247: 1.0220502018928528\n",
      "248: 0.9568255096673965\n",
      "249: 1.188662439584732\n",
      "250: 0.8431868106126785\n",
      "251: 0.6926270425319672\n",
      "252: 0.8848279118537903\n",
      "253: 1.1934847831726074\n",
      "254: 0.8849447965621948\n",
      "255: 1.167266696691513\n",
      "256: 0.8882027864456177\n",
      "257: 0.9754425287246704\n",
      "258: 1.0599551647901535\n",
      "259: 1.3180747032165527\n",
      "260: 1.081202432513237\n",
      "261: 1.0850764960050583\n",
      "262: 0.8190509974956512\n",
      "263: 1.2559409737586975\n",
      "264: 0.9660269320011139\n",
      "265: 0.8419529497623444\n",
      "266: 1.433043509721756\n",
      "267: 0.9018667042255402\n",
      "268: 0.966979518532753\n",
      "269: 1.4126399159431458\n",
      "270: 1.1500131487846375\n",
      "271: 1.3268640041351318\n",
      "272: 1.1097895503044128\n",
      "273: 0.9214087724685669\n",
      "274: 1.1412025392055511\n",
      "275: 1.0761799812316895\n",
      "276: 1.1422784924507141\n",
      "277: 1.0420345664024353\n",
      "278: 0.7922594100236893\n",
      "279: 1.2146745771169662\n",
      "280: 1.011289343237877\n",
      "281: 1.2553928792476654\n",
      "282: 1.2378339767456055\n",
      "283: 0.6223083883523941\n",
      "284: 1.072339951992035\n",
      "285: 1.3378233313560486\n",
      "286: 1.0121979415416718\n",
      "287: 1.1582571268081665\n",
      "288: 1.0325752049684525\n",
      "289: 1.0019837021827698\n",
      "290: 1.1327374577522278\n",
      "291: 1.150123119354248\n",
      "292: 0.8872935026884079\n",
      "293: 1.1788386106491089\n",
      "294: 1.1316413432359695\n",
      "295: 1.0009405314922333\n",
      "296: 1.0590374767780304\n",
      "297: 0.8580270558595657\n",
      "298: 0.9702320843935013\n",
      "299: 0.8755940049886703\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_breast(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        epoch_loss += mixup_loss.item()\n",
    "        mixup_loss.backward()\n",
    "        optimizer.step()\n",
    "    print('{}: {}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brief-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_breast')\n",
    "model = fc_model()\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_breast'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latin-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        predicts = (torch.sign(outputs) + 1) / 2\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "resident-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9706744868035191\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        predicts = (torch.sign(outputs) + 1) / 2\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-galaxy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
