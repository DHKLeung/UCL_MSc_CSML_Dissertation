{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continental-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21332c814d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.01\n",
    "random_seed = 0\n",
    "epochs = 50\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brown-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_MNIST(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 491.6271392926574 85.36578100640327 576.9929206967354\n",
      "1: 374.68713784217834 24.30430335830897 398.99144120514393\n",
      "2: 350.05674843117595 17.0360284994822 367.0927765369415\n",
      "3: 333.08218491077423 13.032949430984445 346.1151332743466\n",
      "4: 317.34626885131 9.367914246860892 326.7141833808273\n",
      "5: 310.4237865190953 8.223967077356065 318.6477533169091\n",
      "6: 300.4021280584857 6.52410957054235 306.9262374667451\n",
      "7: 303.136484333314 5.92911782633746 309.0656018294394\n",
      "8: 298.60532463062555 4.575507296656724 303.18083213828504\n",
      "9: 294.1804208336398 4.128715713712154 298.30913696531206\n",
      "10: 289.8797692004591 3.4019258978951257 293.28169513866305\n",
      "11: 296.9760133586824 3.937644957943121 300.9136579670012\n",
      "12: 285.940368488431 3.288194603883312 289.2285633273423\n",
      "13: 284.20852211117744 2.9719519262580434 287.180473793298\n",
      "14: 283.759501285851 2.8417343418987002 286.6012351065874\n",
      "15: 283.05042143864557 3.1081287973793224 286.15855006314814\n",
      "16: 272.4553479552269 2.2563930685064406 274.71174117922783\n",
      "17: 275.51149713248014 1.987303573077952 277.49880047515035\n",
      "18: 276.82584793819115 2.060807599198597 278.8866553409025\n",
      "19: 271.0980705022812 1.6048671542594093 272.70293762907386\n",
      "20: 269.46288617001846 1.8095534333479009 271.272439529188\n",
      "21: 273.4293372873217 1.6575129064076464 275.08685011416674\n",
      "22: 259.4595783900004 2.06362685066415 261.5232054400258\n",
      "23: 262.5406152782962 1.5628166446895193 264.1034314725548\n",
      "24: 269.99287989735603 1.7526655194087652 271.74554523453116\n",
      "25: 263.00449621025473 1.11921853127933 264.1237150244415\n",
      "26: 261.6528902705759 1.4261895907875441 263.07907998748124\n",
      "27: 263.8544263802469 1.2376412378616806 265.0920677133836\n",
      "28: 259.94755819346756 1.130162705296243 261.0777205498889\n",
      "29: 261.1005289917812 1.445886219451495 262.5464152796194\n",
      "30: 254.83622445818037 1.200318374510971 256.03654327522963\n",
      "31: 262.90723656862974 1.4542017920703074 264.3614380322397\n",
      "32: 256.1642075832933 1.117615071389082 257.28182239457965\n",
      "33: 256.51770592294633 0.7001044547105266 257.21780977677554\n",
      "34: 256.13428713637404 0.95317514193448 257.0874620794784\n",
      "35: 254.17653658427298 1.048125808219993 255.22466245293617\n",
      "36: 249.4700313201174 0.9217828992914292 250.3918145056814\n",
      "37: 253.81284563988447 1.3287591165026242 255.14160492643714\n",
      "38: 248.63736878708005 0.726554831258909 249.36392337083817\n",
      "39: 249.68271199148148 0.8476193289952789 250.53033163864166\n",
      "40: 253.72355122119188 0.9594172725992394 254.68296840135008\n",
      "41: 255.84528450120706 0.7874498271048651 256.6327341319993\n",
      "42: 252.79837188171223 1.2143809210137988 254.0127525939606\n",
      "43: 252.08627747930586 0.9183674053492723 253.0046445466578\n",
      "44: 248.91905300784856 0.6017379464883561 249.52079120650887\n",
      "45: 249.77254834445193 0.6426667285923031 250.41521563613787\n",
      "46: 253.35806872323155 0.7254812036808289 254.08354967366904\n",
      "47: 246.84677024930716 0.9361488577560522 247.78291899897158\n",
      "48: 251.58087598904967 0.7592033859727962 252.34007891267538\n",
      "49: 250.07304534316063 0.3856390352266317 250.4586844444275\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    epoch_mixup_loss = 0.\n",
    "    epoch_org_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_MNIST(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        \n",
    "        ##\n",
    "        outputs_org = model(inputs)\n",
    "        loss_org = criterion(outputs_org, labels)\n",
    "        total_loss = mixup_loss + loss_org\n",
    "        \n",
    "        epoch_mixup_loss += mixup_loss.item()\n",
    "        epoch_org_loss += loss_org.item()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "        total_loss.backward()\n",
    "        ##\n",
    "        \n",
    "        optimizer.step()\n",
    "    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_org_loss, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_mnist_augment')\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_mnist_augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "competitive-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "victorian-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997333333333334\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-situation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
