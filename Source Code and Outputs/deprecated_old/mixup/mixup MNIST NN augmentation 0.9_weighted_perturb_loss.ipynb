{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continental-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14561dca4d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.01\n",
    "random_seed = 0\n",
    "epochs = 100\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "perturb_loss_weight = 0.9\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brown-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_MNIST(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 470.1770848631859 118.75805700942874 588.9351418726146\n",
      "1: 363.2753583602607 40.32294309232384 403.59830145258456\n",
      "2: 340.96414494141936 29.291717066895217 370.2558620083146\n",
      "3: 324.14756973832846 24.130138478707522 348.277708217036\n",
      "4: 310.9081572033465 20.406810785178095 331.3149679885246\n",
      "5: 304.68116251192987 16.925443799700588 321.60660631163046\n",
      "6: 296.7538055572659 14.892043787054718 311.6458493443206\n",
      "7: 298.8322488274425 13.379987908992916 312.21223673643544\n",
      "8: 296.87279672175646 12.86991740798112 309.7427141297376\n",
      "9: 292.618417955935 11.889841003343463 304.50825895927846\n",
      "10: 289.1293779928237 12.535326374229044 301.66470436705276\n",
      "11: 293.8969321101904 10.634645484853536 304.5315775950439\n",
      "12: 283.46074671112 9.557087684166618 293.0178343952866\n",
      "13: 282.3354913070798 9.343124763574451 291.67861607065424\n",
      "14: 280.3029506020248 8.469661883311346 288.77261248533614\n",
      "15: 280.0944428462535 7.793104259239044 287.88754710549256\n",
      "16: 271.98397089727223 7.967011441476643 279.9509823387489\n",
      "17: 274.81682938337326 7.703954545897432 282.5207839292707\n",
      "18: 275.0092678107321 6.616818870534189 281.6260866812663\n",
      "19: 271.06557704880834 6.430555289727636 277.496132338536\n",
      "20: 268.52888621995226 6.289257570926566 274.8181437908788\n",
      "21: 272.5550520941615 5.295759007742163 277.8508111019037\n",
      "22: 258.3821801021695 5.10456110117957 263.4867412033491\n",
      "23: 261.90335461869836 5.963023506163154 267.8663781248615\n",
      "24: 268.5076233036816 5.4330157248768955 273.9406390285585\n",
      "25: 261.9451495204121 4.872539000760298 266.8176885211724\n",
      "26: 260.31626180931926 5.184088150563184 265.50034995988244\n",
      "27: 262.5250230669044 4.578548590419814 267.1035716573242\n",
      "28: 259.26842937245965 4.671961404266767 263.9403907767264\n",
      "29: 259.49128363560885 4.128395773586817 263.61967940919567\n",
      "30: 254.50612093601376 3.9415410158690065 258.44766195188276\n",
      "31: 261.3237449489534 3.758506608894095 265.0822515578475\n",
      "32: 255.26277418620884 3.7171790411812253 258.97995322739007\n",
      "33: 256.3012670017779 4.166330312611535 260.4675973143894\n",
      "34: 255.65335657354444 3.9918776511913165 259.64523422473576\n",
      "35: 253.60945944860578 3.144273168989457 256.75373261759523\n",
      "36: 249.13184493593872 4.013793513120618 253.14563844905933\n",
      "37: 251.92064063623548 3.6509684648481198 255.5716091010836\n",
      "38: 248.84407693892717 3.91798617283348 252.76206311176065\n",
      "39: 248.5307203726843 3.042439821991138 251.57316019467544\n",
      "40: 252.50854586530477 3.326676470111124 255.8352223354159\n",
      "41: 255.34080345532857 2.997644638759084 258.33844809408765\n",
      "42: 250.36498498916626 2.885159366938751 253.250144356105\n",
      "43: 250.7523104324937 2.8929154656943865 253.64522589818807\n",
      "44: 248.2925522737205 2.8660588801722042 251.1586111538927\n",
      "45: 249.50042926706374 2.7007773112272844 252.20120657829102\n",
      "46: 252.11767786368728 2.9276822856627405 255.04536014935002\n",
      "47: 245.66857584752142 2.75957431999268 248.4281501675141\n",
      "48: 251.67371056973934 3.0797274330980144 254.75343800283736\n",
      "49: 249.70699287950993 3.0799646856612526 252.78695756517118\n",
      "50: 248.1285124644637 2.588172909687273 250.71668537415098\n",
      "51: 247.3124430384487 2.7396442126482725 250.05208725109696\n",
      "52: 250.65010559372604 2.9950991782243364 253.64520477195038\n",
      "53: 240.27657714346424 2.3926690162043087 242.66924615966855\n",
      "54: 251.47523609921336 2.317060687812045 253.7922967870254\n",
      "55: 245.16715019289404 2.4065576558350585 247.5737078487291\n",
      "56: 241.60389422625303 2.3682968058274128 243.97219103208045\n",
      "57: 247.77510415948927 2.8112275559687987 250.58633171545807\n",
      "58: 244.1199316829443 2.4535665813600644 246.57349826430436\n",
      "59: 242.96613575425 2.3202573027811013 245.2863930570311\n",
      "60: 241.4242217009887 2.2142102041398175 243.63843190512853\n",
      "61: 242.77018453925848 2.608181974152103 245.37836651341058\n",
      "62: 240.27327527105808 1.9518648092634976 242.22514008032158\n",
      "63: 241.53374528652057 2.0494313100352883 243.58317659655586\n",
      "64: 244.3989785425365 2.0804447236587293 246.47942326619523\n",
      "65: 236.20531262271106 2.1862848817254417 238.3915975044365\n",
      "66: 243.2592875356786 2.0875272048288025 245.3468147405074\n",
      "67: 244.3841727564577 2.0235525090247393 246.40772526548244\n",
      "68: 237.15562298335135 2.4460289156995714 239.60165189905092\n",
      "69: 235.6077948345337 2.2234409030061215 237.83123573753983\n",
      "70: 246.34063469152898 2.224395183380693 248.56502987490967\n",
      "71: 240.08411933109164 2.0080046611255966 242.09212399221724\n",
      "72: 235.3328953180462 2.19377720792545 237.52667252597166\n",
      "73: 239.30269451066852 2.2638432460371405 241.56653775670566\n",
      "74: 236.65777410380542 2.0507760154432617 238.70855011924868\n",
      "75: 235.88862949889153 2.097198585048318 237.98582808393985\n",
      "76: 238.10421374160796 1.4764785245642997 239.58069226617226\n",
      "77: 243.94727533869445 2.0302242042380385 245.9774995429325\n",
      "78: 235.38089516200125 2.38193116360344 237.7628263256047\n",
      "79: 242.42138646636158 2.336828842002433 244.75821530836402\n",
      "80: 239.01138135092333 1.6223753603408113 240.63375671126414\n",
      "81: 239.37715156003833 1.4589130327221937 240.83606459276052\n",
      "82: 235.32933477219194 2.089001686836127 237.41833645902807\n",
      "83: 239.08614384755492 1.649740320746787 240.7358841683017\n",
      "84: 235.73441639449447 2.080362320295535 237.81477871479\n",
      "85: 244.2576494384557 1.8863620306365192 246.14401146909222\n",
      "86: 226.0564438039437 2.235471951251384 228.29191575519508\n",
      "87: 234.40146833658218 1.5483585181063972 235.94982685468858\n",
      "88: 235.76721873972565 2.0078779365867376 237.7750966763124\n",
      "89: 234.8731867391616 1.6812300715246238 236.55441681068623\n",
      "90: 228.5054983482696 1.549503343354445 230.05500169162406\n",
      "91: 228.7278464026749 1.4866658433456905 230.2145122460206\n",
      "92: 237.60703293420374 1.3585837710415944 238.96561670524534\n",
      "93: 242.12541550770402 1.478686145215761 243.60410165291978\n",
      "94: 231.38739785179496 1.5666774497949518 232.9540753015899\n",
      "95: 232.1687051076442 1.2392470968188718 233.40795220446307\n",
      "96: 239.1075051035732 1.9806289548287168 241.08813405840192\n",
      "97: 231.27535874210298 1.4841307679889724 232.75948951009195\n",
      "98: 230.1791866988642 1.667528330348432 231.84671502921265\n",
      "99: 225.61688511958346 1.278878003358841 226.8957631229423\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    epoch_mixup_loss = 0.\n",
    "    epoch_org_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_MNIST(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        \n",
    "        ##\n",
    "        outputs_org = model(inputs)\n",
    "        loss_org = criterion(outputs_org, labels)\n",
    "        weighted_total_loss = mixup_loss * perturb_loss_weight + loss_org * (1 - perturb_loss_weight)\n",
    "        \n",
    "        epoch_mixup_loss += mixup_loss.item()\n",
    "        epoch_org_loss += loss_org.item()\n",
    "        \n",
    "        epoch_loss += (mixup_loss.item() + loss_org.item())\n",
    "        \n",
    "        weighted_total_loss.backward()\n",
    "        ##\n",
    "        \n",
    "        optimizer.step()\n",
    "    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_org_loss, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_mnist_augment')\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_mnist_augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "competitive-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9954\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "victorian-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-situation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
