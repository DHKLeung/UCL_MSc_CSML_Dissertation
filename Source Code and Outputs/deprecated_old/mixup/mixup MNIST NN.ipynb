{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continental-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x178832ef4d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.01\n",
    "random_seed = 0\n",
    "epochs = 50\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brown-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_MNIST(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 473.769829839468\n",
      "1: 361.91803466528654\n",
      "2: 338.3119442462921\n",
      "3: 320.7842643484473\n",
      "4: 307.9343439415097\n",
      "5: 301.80080972984433\n",
      "6: 293.51977694779634\n",
      "7: 294.8360937945545\n",
      "8: 293.0151604488492\n",
      "9: 288.97041629999876\n",
      "10: 285.5374068170786\n",
      "11: 290.3960692919791\n",
      "12: 280.1688536927104\n",
      "13: 279.02523909136653\n",
      "14: 277.4751128666103\n",
      "15: 277.6376750841737\n",
      "16: 267.88091595843434\n",
      "17: 271.8669027425349\n",
      "18: 271.67082326859236\n",
      "19: 268.0029690042138\n",
      "20: 265.29177652671933\n",
      "21: 270.3418270908296\n",
      "22: 255.613528188318\n",
      "23: 258.6215535029769\n",
      "24: 265.19374030455947\n",
      "25: 258.6382108181715\n",
      "26: 257.89798752963543\n",
      "27: 259.51313184015453\n",
      "28: 256.09286912716925\n",
      "29: 256.03573111630976\n",
      "30: 251.01085766777396\n",
      "31: 258.6566213481128\n",
      "32: 252.85793170705438\n",
      "33: 253.03797079995275\n",
      "34: 252.71571597456932\n",
      "35: 250.31602680683136\n",
      "36: 246.26889471709728\n",
      "37: 250.06285435333848\n",
      "38: 245.5783874616027\n",
      "39: 245.3623173078522\n",
      "40: 250.20899488031864\n",
      "41: 252.12295530550182\n",
      "42: 247.78494908474386\n",
      "43: 248.22035155445337\n",
      "44: 246.10754569340497\n",
      "45: 247.72396226227283\n",
      "46: 249.27557321079075\n",
      "47: 242.86219900287688\n",
      "48: 249.20861322805285\n",
      "49: 247.14124336838722\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_MNIST(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        epoch_loss += mixup_loss.item()\n",
    "        mixup_loss.backward()\n",
    "        optimizer.step()\n",
    "    print('{}: {}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_mnist')\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_mnist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "competitive-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "victorian-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99595\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-situation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
