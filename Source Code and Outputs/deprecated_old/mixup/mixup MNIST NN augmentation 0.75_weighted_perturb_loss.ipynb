{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continental-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x209c90c04d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.01\n",
    "random_seed = 0\n",
    "epochs = 100\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "perturb_loss_weight = 0.75\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brown-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_MNIST(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 476.9724363386631 104.4012790210545 581.3737153597176\n",
      "1: 370.14227997139096 32.70804162602872 402.8503215974197\n",
      "2: 346.73022370412946 22.982035391032696 369.71225909516215\n",
      "3: 328.3877817951143 18.121711362036876 346.50949315715116\n",
      "4: 314.4301942512393 14.184749023406766 328.61494327464607\n",
      "5: 307.83533869870007 12.12002641451545 319.9553651132155\n",
      "6: 300.1637667603791 10.610098465287592 310.77386522566667\n",
      "7: 301.6818606071174 9.57962723413948 311.2614878412569\n",
      "8: 299.1389101948589 8.738341974152718 307.8772521690116\n",
      "9: 293.6350624281913 7.207841809053207 300.8429042372445\n",
      "10: 289.52381127141416 6.463142732274719 295.9869540036889\n",
      "11: 294.92984687164426 6.571158773556817 301.5010056452011\n",
      "12: 284.7079503312707 5.906006788223749 290.61395711949444\n",
      "13: 283.02307272702456 5.91314053957467 288.9362132665992\n",
      "14: 281.046838786453 4.705114221636904 285.7519530080899\n",
      "15: 281.31459284666926 4.547650308872107 285.86224315554136\n",
      "16: 273.13646397180855 4.658730904688127 277.7951948764967\n",
      "17: 275.3701615482569 4.340604810626246 279.7107663588831\n",
      "18: 275.4002414923161 3.4174883964878973 278.817729888804\n",
      "19: 271.2222602851689 3.106108825217234 274.3283691103861\n",
      "20: 268.4924657577649 3.1628230668138713 271.65528882457875\n",
      "21: 273.1917786728591 3.200612040964188 276.39239071382326\n",
      "22: 258.23156495927833 2.887197754724184 261.1187627140025\n",
      "23: 261.04049368202686 2.853048877470428 263.8935425594973\n",
      "24: 268.70988734811544 2.8500973270856775 271.5599846752011\n",
      "25: 261.84763964265585 2.851440928556258 264.6990805712121\n",
      "26: 260.4368646964431 2.4625402556266636 262.89940495206974\n",
      "27: 262.2284234005492 2.2783083244867157 264.50673172503593\n",
      "28: 258.8811692632735 2.117026256979443 260.9981955202529\n",
      "29: 259.0669808322564 2.3235913588723633 261.39057219112874\n",
      "30: 253.75089334277436 2.3354222877242137 256.0863156304986\n",
      "31: 260.96189465373755 2.0442719134152867 263.00616656715283\n",
      "32: 254.6245265668258 1.7514311159902718 256.3759576828161\n",
      "33: 256.30322079826146 2.2239948518108577 258.5272156500723\n",
      "34: 255.9837060328573 2.68744008577778 258.6711461186351\n",
      "35: 252.88883335888386 1.9201058122853283 254.8089391711692\n",
      "36: 248.44314964301884 1.710155327047687 250.15330497006653\n",
      "37: 252.44717140495777 2.126956621214049 254.57412802617182\n",
      "38: 248.2689692582935 2.063174115231959 250.33214337352547\n",
      "39: 248.41007635183632 1.7746810142998584 250.18475736613618\n",
      "40: 252.25373521726578 1.7774503220571205 254.0311855393229\n",
      "41: 254.96324093593284 1.7338451484392863 256.69708608437213\n",
      "42: 250.36288874596357 1.6728205731778871 252.03570931914146\n",
      "43: 250.77835796773434 1.4630942195653915 252.24145218729973\n",
      "44: 248.56136994762346 1.5358585760986898 250.09722852372215\n",
      "45: 249.30134382029064 1.7791955595021136 251.08053937979275\n",
      "46: 252.4866658449173 1.5934638226171955 254.0801296675345\n",
      "47: 245.36024345830083 1.2736880638403818 246.6339315221412\n",
      "48: 250.6171290166676 1.4732587437611073 252.0903877604287\n",
      "49: 249.6885951012373 1.228932178026298 250.9175272792636\n",
      "50: 247.6346118412912 1.2581148325407412 248.89272667383193\n",
      "51: 246.59333770442754 1.1806385478848824 247.77397625231242\n",
      "52: 251.03626236133277 1.2384385562909301 252.2747009176237\n",
      "53: 240.4703267030418 1.308748177398229 241.77907488044002\n",
      "54: 251.05734658241272 1.3552499494107906 252.4125965318235\n",
      "55: 245.3784455023706 1.4001929750229465 246.77863847739354\n",
      "56: 242.57374610379338 1.6503491449402645 244.22409524873365\n",
      "57: 248.21931019052863 1.0752609974588268 249.29457118798746\n",
      "58: 244.4075207039714 1.2675513467402197 245.6750720507116\n",
      "59: 243.02797576994635 1.1605086890049279 244.18848445895128\n",
      "60: 241.25177397113293 1.2937220089370385 242.54549598006997\n",
      "61: 242.6777149392292 1.1002450681407936 243.77796000736998\n",
      "62: 241.14522255957127 1.5681792202958604 242.71340177986713\n",
      "63: 241.8088282556273 0.9313963838212658 242.74022463944857\n",
      "64: 244.082784447819 1.1551646955485921 245.2379491433676\n",
      "65: 235.82649268768728 0.9759828346723225 236.8024755223596\n",
      "66: 243.56003297376446 1.2815793465124443 244.8416123202769\n",
      "67: 245.2826439102646 1.0446484059211798 246.32729231618578\n",
      "68: 236.64917594194412 1.0501764055370586 237.69935234748118\n",
      "69: 235.82876307796687 1.089844356465619 236.9186074344325\n",
      "70: 246.5278830495663 1.031026386161102 247.5589094357274\n",
      "71: 240.50289205089211 1.0814185872732196 241.58431063816533\n",
      "72: 236.03880276717246 1.2708630734996404 237.3096658406721\n",
      "73: 239.94029406504706 1.3158225617080461 241.2561166267551\n",
      "74: 235.94774755090475 0.8347593354119454 236.7825068863167\n",
      "75: 235.6952191106975 1.0740178185515106 236.76923692924902\n",
      "76: 238.1614295579493 0.9635866401658859 239.1250161981152\n",
      "77: 243.46023823227733 0.7876181775645819 244.24785640984192\n",
      "78: 235.26897078566253 1.0736399852467002 236.34261077090923\n",
      "79: 242.55547668365762 1.0169533072330523 243.57242999089067\n",
      "80: 239.51653518900275 0.9547170152654871 240.47125220426824\n",
      "81: 239.88261456787586 1.1741132432362065 241.05672781111207\n",
      "82: 236.08264084043913 0.9554746762441937 237.03811551668332\n",
      "83: 238.88847864046693 0.9567220113240182 239.84520065179095\n",
      "84: 235.65682332403958 1.079633778979769 236.73645710301935\n",
      "85: 244.11578449839726 0.9824355466553243 245.09822004505259\n",
      "86: 226.0326704988256 0.9276042876590509 226.96027478648466\n",
      "87: 234.51327371201478 0.7410845605627401 235.25435827257752\n",
      "88: 235.676540391054 0.9753142050612951 236.6518545961153\n",
      "89: 235.2561439666897 0.8239494181470945 236.0800933848368\n",
      "90: 229.24805765529163 0.9679435477592051 230.21600120305084\n",
      "91: 229.08035562187433 0.9898101358267013 230.07016575770103\n",
      "92: 238.0017097685486 0.7930927376437467 238.79480250619235\n",
      "93: 242.27064789272845 0.7400236034300178 243.01067149615847\n",
      "94: 231.59482968971133 1.0902905903640203 232.68512028007535\n",
      "95: 233.32063896860927 1.0143928647303255 234.3350318333396\n",
      "96: 238.494991350919 0.9757893715723185 239.47078072249133\n",
      "97: 231.2393743833527 0.8635131359042134 232.1028875192569\n",
      "98: 230.71992424089694 0.9557458135968773 231.67567005449382\n",
      "99: 226.2165892161429 0.7275167754560243 226.94410599159892\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    epoch_mixup_loss = 0.\n",
    "    epoch_org_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_MNIST(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        \n",
    "        ##\n",
    "        outputs_org = model(inputs)\n",
    "        loss_org = criterion(outputs_org, labels)\n",
    "        weighted_total_loss = mixup_loss * perturb_loss_weight + loss_org * (1 - perturb_loss_weight)\n",
    "        \n",
    "        epoch_mixup_loss += mixup_loss.item()\n",
    "        epoch_org_loss += loss_org.item()\n",
    "        \n",
    "        epoch_loss += (mixup_loss.item() + loss_org.item())\n",
    "        \n",
    "        weighted_total_loss.backward()\n",
    "        ##\n",
    "        \n",
    "        optimizer.step()\n",
    "    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_org_loss, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_mnist_augment')\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_mnist_augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "competitive-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9944\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "victorian-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995833333333334\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-situation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
