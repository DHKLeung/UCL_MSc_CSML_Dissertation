{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continental-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ed186604d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.01\n",
    "random_seed = 0\n",
    "epochs = 100\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "perturb_loss_weight = 0.99\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brown-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_MNIST(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 471.8203232139349 136.1585578545928 607.9788810685277\n",
      "1: 360.77934174984694 50.98222406767309 411.76156581752\n",
      "2: 339.86251078918576 39.5859357137233 379.44844650290906\n",
      "3: 322.3417670801282 32.587649431079626 354.9294165112078\n",
      "4: 309.5064204223454 29.007666064426303 338.5140864867717\n",
      "5: 303.36444502696395 25.610553317703307 328.97499834466726\n",
      "6: 295.5371214672923 23.851925529539585 319.3890469968319\n",
      "7: 297.2428041771054 21.927805127575994 319.1706093046814\n",
      "8: 295.19785227254033 19.919605945702642 315.117458218243\n",
      "9: 291.4060556665063 19.8000076841563 311.2060633506626\n",
      "10: 286.7951468266547 18.707758427597582 305.50290525425225\n",
      "11: 292.3859700411558 19.03554828558117 311.421518326737\n",
      "12: 282.1672887764871 17.510343664325774 299.6776324408129\n",
      "13: 280.7929543349892 16.79401963111013 297.5869739660993\n",
      "14: 278.9109611213207 15.948838365264237 294.85979948658496\n",
      "15: 278.7968161404133 15.897826201282442 294.6946423416957\n",
      "16: 270.1359643228352 14.129548067692667 284.2655123905279\n",
      "17: 272.8342451490462 13.225851881317794 286.060097030364\n",
      "18: 272.75990580394864 13.503913494758308 286.26381929870695\n",
      "19: 269.2680297791958 12.960621402598917 282.2286511817947\n",
      "20: 266.96648465283215 12.796740013174713 279.76322466600686\n",
      "21: 271.1289333552122 12.871680640615523 284.00061399582773\n",
      "22: 256.5503543317318 11.279462610837072 267.82981694256887\n",
      "23: 259.8590278606862 11.129218167159706 270.9882460278459\n",
      "24: 266.74811152741313 11.05314981751144 277.80126134492457\n",
      "25: 260.1798154246062 10.990871251560748 271.17068667616695\n",
      "26: 258.6908041536808 10.119901350233704 268.8107055039145\n",
      "27: 261.33617028966546 10.220380116254091 271.55655040591955\n",
      "28: 257.2721505202353 9.41058249771595 266.68273301795125\n",
      "29: 257.61214174702764 8.930286963004619 266.54242871003225\n",
      "30: 252.48717369697988 9.033699898980558 261.52087359596044\n",
      "31: 259.26290548965335 8.575962339062244 267.8388678287156\n",
      "32: 253.5363066457212 8.315798288211226 261.8521049339324\n",
      "33: 254.4982254654169 9.063785306643695 263.5620107720606\n",
      "34: 254.23873112536967 9.144129767082632 263.3828608924523\n",
      "35: 251.11334446072578 8.065288212615997 259.1786326733418\n",
      "36: 247.26921102032065 8.21350917313248 255.48272019345313\n",
      "37: 250.57237791270018 7.7941972692497075 258.3665751819499\n",
      "38: 246.64833221957088 8.259680591989309 254.90801281156018\n",
      "39: 246.6554681332782 8.161967345513403 254.8174354787916\n",
      "40: 251.3964247815311 7.267454409506172 258.66387919103727\n",
      "41: 253.81147365644574 7.406410174444318 261.21788383089006\n",
      "42: 249.12723789270967 6.88050992321223 256.0077478159219\n",
      "43: 249.41131595522165 6.999358707573265 256.4106746627949\n",
      "44: 246.89277797564864 6.950140872504562 253.8429188481532\n",
      "45: 248.78162214253098 7.250740918330848 256.0323630608618\n",
      "46: 250.33215511217713 7.3665168904699385 257.6986720026471\n",
      "47: 243.92807170189917 7.316522063687444 251.24459376558661\n",
      "48: 249.80535067990422 6.63457260094583 256.43992328085005\n",
      "49: 248.43313696235418 6.965521947015077 255.39865890936926\n",
      "50: 246.9455401133746 7.432236053049564 254.37777616642416\n",
      "51: 245.54626387357712 7.013846084009856 252.56010995758697\n",
      "52: 249.46187994256616 7.093978965654969 256.5558589082211\n",
      "53: 239.18067642115057 6.764498109929264 245.94517453107983\n",
      "54: 250.39942966401577 6.6908269645646214 257.0902566285804\n",
      "55: 243.84444097988307 6.819007977843285 250.66344895772636\n",
      "56: 241.02527954429388 6.816016570199281 247.84129611449316\n",
      "57: 247.06936704739928 7.283834183122963 254.35320123052225\n",
      "58: 243.14695623517036 6.558185678906739 249.7051419140771\n",
      "59: 241.58667615614831 6.1300167022272944 247.7166928583756\n",
      "60: 239.6674000751227 6.11510761315003 245.78250768827274\n",
      "61: 241.4298006836325 6.20901290839538 247.63881359202787\n",
      "62: 240.18228053674102 6.293249095324427 246.47552963206545\n",
      "63: 240.68820811621845 6.175141683313996 246.86334979953244\n",
      "64: 243.74911324959248 5.9350871834903955 249.68420043308288\n",
      "65: 235.73524564690888 6.457833358086646 242.19307900499552\n",
      "66: 242.23468562494963 5.600590834859759 247.8352764598094\n",
      "67: 244.13628596253693 5.727234755642712 249.86352071817964\n",
      "68: 236.41645303368568 6.081254198215902 242.4977072319016\n",
      "69: 235.14975562505424 5.4422107096761465 240.5919663347304\n",
      "70: 245.49382321257144 5.152804581681266 250.6466277942527\n",
      "71: 239.11716848798096 5.086473800241947 244.2036422882229\n",
      "72: 234.741437247023 4.538604521891102 239.2800417689141\n",
      "73: 237.83174346853048 4.512759919743985 242.34450338827446\n",
      "74: 235.00520022027194 4.9363654418848455 239.9415656621568\n",
      "75: 235.19135552551597 4.620766746578738 239.8121222720947\n",
      "76: 236.87137245200574 4.794121706392616 241.66549415839836\n",
      "77: 243.14247442688793 5.400934078730643 248.54340850561857\n",
      "78: 234.04085263609886 5.046001123031601 239.08685375913046\n",
      "79: 241.4592685420066 4.922346384031698 246.3816149260383\n",
      "80: 237.7658625692129 4.94381055701524 242.70967312622815\n",
      "81: 238.93389545753598 4.691085896687582 243.62498135422356\n",
      "82: 235.40090300422162 5.231900197453797 240.63280320167542\n",
      "83: 238.6388695910573 4.851505011320114 243.49037460237741\n",
      "84: 234.55963800288737 5.062917487230152 239.62255549011752\n",
      "85: 244.2252506427467 5.374811357352883 249.60006200009957\n",
      "86: 225.373164284043 4.798770319670439 230.17193460371345\n",
      "87: 233.54434800334275 4.731250727782026 238.27559873112477\n",
      "88: 235.01366354804486 5.21698163356632 240.23064518161118\n",
      "89: 234.18997392989695 4.331037716008723 238.52101164590567\n",
      "90: 228.4300464587286 4.772765703499317 233.20281216222793\n",
      "91: 228.2808144390583 4.55980397388339 232.8406184129417\n",
      "92: 236.69376911967993 4.447364223422483 241.1411333431024\n",
      "93: 242.28936630487442 4.6495667663402855 246.9389330712147\n",
      "94: 231.40371268242598 4.85167908272706 236.25539176515304\n",
      "95: 232.10870006866753 4.669698965037242 236.77839903370477\n",
      "96: 237.99862290732563 4.858784753829241 242.85740766115487\n",
      "97: 230.56724424287677 4.7169213984161615 235.28416564129293\n",
      "98: 229.67532677436247 4.351276509696618 234.0266032840591\n",
      "99: 225.54584189131856 4.279288014862686 229.82512990618125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    epoch_mixup_loss = 0.\n",
    "    epoch_org_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_MNIST(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        \n",
    "        ##\n",
    "        outputs_org = model(inputs)\n",
    "        loss_org = criterion(outputs_org, labels)\n",
    "        weighted_total_loss = mixup_loss * perturb_loss_weight + loss_org * (1 - perturb_loss_weight)\n",
    "        \n",
    "        epoch_mixup_loss += mixup_loss.item()\n",
    "        epoch_org_loss += loss_org.item()\n",
    "        \n",
    "        epoch_loss += (mixup_loss.item() + loss_org.item())\n",
    "        \n",
    "        weighted_total_loss.backward()\n",
    "        ##\n",
    "        \n",
    "        optimizer.step()\n",
    "    print('{}: {} {} {}'.format(epoch, epoch_mixup_loss, epoch_org_loss, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_mnist_augment')\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_mnist_augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "competitive-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "victorian-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994166666666666\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-situation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
