{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romantic-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silver-clear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22c8aab04d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # can omit\n",
    "    transforms.RandomHorizontalFlip(),  # can omit\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.4914, 0.4822, 0.4465),\n",
    "        (0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.4914, 0.4822, 0.4465),\n",
    "        (0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.1\n",
    "random_seed = 0\n",
    "epochs = 100\n",
    "L2_decay = 1e-4\n",
    "alpha = 1.\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relative-mobility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "starting-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__['ResNet18']()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contemporary-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_cifar10(inputs, labels, alpha):\n",
    "    lmbda = torch.distributions.beta.Beta(alpha, alpha).sample()\n",
    "    batch_size = labels.size(0)\n",
    "    idx = torch.randperm(batch_size)\n",
    "    mixup_inputs = lmbda * inputs + (1 - lmbda) * inputs[idx]\n",
    "    labels_b = labels[idx]\n",
    "    return mixup_inputs, labels, labels_b, lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "right-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(criterion, predicts, labels, labels_b, lmbda):\n",
    "    mixup_loss = lmbda * criterion(predicts, labels) + (1 - lmbda) * criterion(predicts, labels_b)\n",
    "    return mixup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "written-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 788.8078310489655\n",
      "1: 686.7634365558624\n",
      "2: 616.3969045877457\n",
      "3: 588.2611461281776\n",
      "4: 538.7559841275215\n",
      "5: 529.1499211788177\n",
      "6: 507.4149586260319\n",
      "7: 497.6203532218933\n",
      "8: 469.34546449780464\n",
      "9: 476.28263008594513\n",
      "10: 468.4674711227417\n",
      "11: 460.5329996943474\n",
      "12: 458.1390701830387\n",
      "13: 470.8426288664341\n",
      "14: 449.1597504019737\n",
      "15: 441.47181321680546\n",
      "16: 430.4203013330698\n",
      "17: 433.1848093420267\n",
      "18: 419.7524399161339\n",
      "19: 439.73905485868454\n",
      "20: 431.22776083648205\n",
      "21: 436.2507918328047\n",
      "22: 417.0537496507168\n",
      "23: 418.8140291571617\n",
      "24: 415.00898200273514\n",
      "25: 402.5538599193096\n",
      "26: 409.8948245048523\n",
      "27: 406.50630354881287\n",
      "28: 402.128609418869\n",
      "29: 404.8351937830448\n",
      "30: 405.0635282546282\n",
      "31: 418.59043857455254\n",
      "32: 405.0280885845423\n",
      "33: 406.9426494538784\n",
      "34: 403.2458438426256\n",
      "35: 402.3958051651716\n",
      "36: 401.69816586375237\n",
      "37: 397.0042129009962\n",
      "38: 403.1644684225321\n",
      "39: 398.1817757189274\n",
      "40: 395.95755212008953\n",
      "41: 394.3507607281208\n",
      "42: 390.5644769370556\n",
      "43: 377.47967006266117\n",
      "44: 388.4166259765625\n",
      "45: 391.33299247920513\n",
      "46: 395.2447343468666\n",
      "47: 384.2592112123966\n",
      "48: 399.15910913050175\n",
      "49: 389.5008856728673\n",
      "50: 378.24819502979517\n",
      "51: 392.16009348630905\n",
      "52: 401.4697576612234\n",
      "53: 376.0796244889498\n",
      "54: 368.2903111279011\n",
      "55: 393.03901782631874\n",
      "56: 386.7366182357073\n",
      "57: 386.0383922159672\n",
      "58: 388.2110616713762\n",
      "59: 381.6049929112196\n",
      "60: 393.4796608015895\n",
      "61: 386.6482673585415\n",
      "62: 380.4365999698639\n",
      "63: 371.6652540639043\n",
      "64: 377.44962728768587\n",
      "65: 376.7262414544821\n",
      "66: 391.1800774484873\n",
      "67: 383.8585011959076\n",
      "68: 374.7035828381777\n",
      "69: 383.4918341040611\n",
      "70: 384.85091868042946\n",
      "71: 375.9695103764534\n",
      "72: 379.1575223207474\n",
      "73: 378.010061070323\n",
      "74: 377.7702442109585\n",
      "75: 373.2204679995775\n",
      "76: 381.56987465918064\n",
      "77: 380.3726328238845\n",
      "78: 376.943330720067\n",
      "79: 364.29565155506134\n",
      "80: 379.01737147569656\n",
      "81: 371.1198476180434\n",
      "82: 371.9812926054001\n",
      "83: 373.51735332608223\n",
      "84: 369.78463477641344\n",
      "85: 363.8040432333946\n",
      "86: 370.2520796582103\n",
      "87: 378.02638401836157\n",
      "88: 392.1252225935459\n",
      "89: 369.0102675706148\n",
      "90: 375.7757030874491\n",
      "91: 367.90530962496996\n",
      "92: 371.18593211472034\n",
      "93: 362.91548758745193\n",
      "94: 384.91772512346506\n",
      "95: 365.1116349324584\n",
      "96: 379.2695232182741\n",
      "97: 376.23873192071915\n",
      "98: 374.8858015090227\n",
      "99: 364.0366960912943\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        mixup_inputs, labels, labels_b, lmbda = mixup_cifar10(inputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mixup_inputs)\n",
    "        mixup_loss = mixup_criterion(criterion, outputs, labels, labels_b, lmbda)\n",
    "        epoch_loss += mixup_loss.item()\n",
    "        mixup_loss.backward()\n",
    "        optimizer.step()\n",
    "    print('{}: {}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frozen-damage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './mixup_model_pytorch_cifar10')\n",
    "model = models.__dict__['ResNet18']()\n",
    "model.load_state_dict(torch.load('./mixup_model_pytorch_cifar10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aboriginal-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-orlando",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
