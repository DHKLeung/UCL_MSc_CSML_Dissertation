{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proprietary-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from load_data import load_skl_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silent-johns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2123d942470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration and Hyperparameters\n",
    "\"\"\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)  # default all in GPU\n",
    "\n",
    "batch_size = 128\n",
    "step_size = 0.005\n",
    "random_seed = 0\n",
    "epochs = 300\n",
    "L2_decay = 1e-4\n",
    "gauss_vicinal_std = 0.25\n",
    "\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compressed-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_skl_data('breast_cancer')\n",
    "test_data = np.vstack((val_data, test_data))\n",
    "test_labels = np.hstack((val_labels, test_labels))\n",
    "train_data = torch.from_numpy(train_data).type(torch.FloatTensor)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "test_data = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "train_mean = torch.mean(train_data, 0)\n",
    "train_std = torch.std(train_data, 0)\n",
    "train_data = (train_data - train_mean) / train_std\n",
    "test_data = (test_data - train_mean) / train_std\n",
    "train_set = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "test_set = torch.utils.data.TensorDataset(test_data, test_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "buried-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_model(\n",
      "  (fc1): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class fc_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fc_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "    def forward(self, inputs):\n",
    "        fc1_out = F.tanh(self.fc1(inputs))\n",
    "        fc2_out = F.tanh(self.fc2(fc1_out))\n",
    "        fc3_out = F.tanh(self.fc3(fc2_out))\n",
    "        fc4_out = self.fc4(fc3_out)\n",
    "        return fc4_out\n",
    "\n",
    "model = fc_model()\n",
    "print(model)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=step_size, momentum=0.9, weight_decay=L2_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protective-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_vicinal(inputs, gauss_vicinal_std):\n",
    "    inputs_gauss = torch.normal(inputs, gauss_vicinal_std)\n",
    "    return inputs_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pediatric-namibia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\Python3_8\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.0421253442764282\n",
      "1: 2.009264349937439\n",
      "2: 1.9533313512802124\n",
      "3: 1.8817859292030334\n",
      "4: 1.7922104597091675\n",
      "5: 1.712353229522705\n",
      "6: 1.6141722798347473\n",
      "7: 1.503759652376175\n",
      "8: 1.3915450870990753\n",
      "9: 1.267835110425949\n",
      "10: 1.142247051000595\n",
      "11: 1.0372871458530426\n",
      "12: 0.9194979071617126\n",
      "13: 0.8356046378612518\n",
      "14: 0.7401711195707321\n",
      "15: 0.6593212783336639\n",
      "16: 0.5867848545312881\n",
      "17: 0.5501986593008041\n",
      "18: 0.5016821920871735\n",
      "19: 0.46105213463306427\n",
      "20: 0.4221096932888031\n",
      "21: 0.40139371901750565\n",
      "22: 0.35830938816070557\n",
      "23: 0.36958104372024536\n",
      "24: 0.3491109535098076\n",
      "25: 0.3126230835914612\n",
      "26: 0.28041867911815643\n",
      "27: 0.27386321872472763\n",
      "28: 0.2565389946103096\n",
      "29: 0.28208183497190475\n",
      "30: 0.23717157170176506\n",
      "31: 0.23274408653378487\n",
      "32: 0.2577847093343735\n",
      "33: 0.23716270178556442\n",
      "34: 0.24095140770077705\n",
      "35: 0.21766643226146698\n",
      "36: 0.21291353926062584\n",
      "37: 0.2113146260380745\n",
      "38: 0.2093324288725853\n",
      "39: 0.21020904928445816\n",
      "40: 0.20693091303110123\n",
      "41: 0.21199709549546242\n",
      "42: 0.1952904351055622\n",
      "43: 0.18449699878692627\n",
      "44: 0.1847531609237194\n",
      "45: 0.20097487419843674\n",
      "46: 0.20290301367640495\n",
      "47: 0.19307976588606834\n",
      "48: 0.19003946334123611\n",
      "49: 0.19350001960992813\n",
      "50: 0.20113293081521988\n",
      "51: 0.18834847584366798\n",
      "52: 0.21564405411481857\n",
      "53: 0.16894182190299034\n",
      "54: 0.17581559345126152\n",
      "55: 0.1768788918852806\n",
      "56: 0.1882907599210739\n",
      "57: 0.15602281130850315\n",
      "58: 0.16751126572489738\n",
      "59: 0.15750568732619286\n",
      "60: 0.19674058072268963\n",
      "61: 0.17385586351156235\n",
      "62: 0.1520985495299101\n",
      "63: 0.17976586148142815\n",
      "64: 0.15276887640357018\n",
      "65: 0.17052093520760536\n",
      "66: 0.14245488122105598\n",
      "67: 0.1595313474535942\n",
      "68: 0.14288263209164143\n",
      "69: 0.17722518555819988\n",
      "70: 0.16375058516860008\n",
      "71: 0.14516760781407356\n",
      "72: 0.15305438823997974\n",
      "73: 0.15217426419258118\n",
      "74: 0.16208766028285027\n",
      "75: 0.13803700357675552\n",
      "76: 0.1270046140998602\n",
      "77: 0.16269315034151077\n",
      "78: 0.18242983520030975\n",
      "79: 0.13854827918112278\n",
      "80: 0.17658668011426926\n",
      "81: 0.16537315770983696\n",
      "82: 0.14014283195137978\n",
      "83: 0.16499310731887817\n",
      "84: 0.1417939718812704\n",
      "85: 0.1550883874297142\n",
      "86: 0.2199893556535244\n",
      "87: 0.14943812787532806\n",
      "88: 0.1834043189883232\n",
      "89: 0.15714016929268837\n",
      "90: 0.1089512063190341\n",
      "91: 0.14696680754423141\n",
      "92: 0.13406153209507465\n",
      "93: 0.16287461668252945\n",
      "94: 0.13294880837202072\n",
      "95: 0.16315181367099285\n",
      "96: 0.14088257402181625\n",
      "97: 0.16175398416817188\n",
      "98: 0.15293999761343002\n",
      "99: 0.14561336487531662\n",
      "100: 0.14611055329442024\n",
      "101: 0.14714407920837402\n",
      "102: 0.16494054719805717\n",
      "103: 0.12373138032853603\n",
      "104: 0.14439972676336765\n",
      "105: 0.16098232194781303\n",
      "106: 0.12811435386538506\n",
      "107: 0.16777386888861656\n",
      "108: 0.11600632965564728\n",
      "109: 0.12347199022769928\n",
      "110: 0.14422307908535004\n",
      "111: 0.12557991780340672\n",
      "112: 0.10052366461604834\n",
      "113: 0.13286085985600948\n",
      "114: 0.17191202193498611\n",
      "115: 0.12674930412322283\n",
      "116: 0.12627523113042116\n",
      "117: 0.11264309380203485\n",
      "118: 0.15080953761935234\n",
      "119: 0.15316761657595634\n",
      "120: 0.14222098141908646\n",
      "121: 0.11447760835289955\n",
      "122: 0.11022508144378662\n",
      "123: 0.12696517072618008\n",
      "124: 0.14240866899490356\n",
      "125: 0.15260988473892212\n",
      "126: 0.19022833742201328\n",
      "127: 0.12845319136977196\n",
      "128: 0.11087424494326115\n",
      "129: 0.11685887910425663\n",
      "130: 0.1391757596284151\n",
      "131: 0.12900543585419655\n",
      "132: 0.1318944077938795\n",
      "133: 0.1417805515229702\n",
      "134: 0.14023548364639282\n",
      "135: 0.1220845989882946\n",
      "136: 0.11047048028558493\n",
      "137: 0.1702294461429119\n",
      "138: 0.1130435261875391\n",
      "139: 0.13696548901498318\n",
      "140: 0.16194581054151058\n",
      "141: 0.10861674509942532\n",
      "142: 0.13930583372712135\n",
      "143: 0.11230271309614182\n",
      "144: 0.10483894869685173\n",
      "145: 0.12624353356659412\n",
      "146: 0.12664992921054363\n",
      "147: 0.10617521964013577\n",
      "148: 0.15136081352829933\n",
      "149: 0.12095937225967646\n",
      "150: 0.15945104882121086\n",
      "151: 0.11090226098895073\n",
      "152: 0.12637867778539658\n",
      "153: 0.12606767565011978\n",
      "154: 0.1345231719315052\n",
      "155: 0.08864740654826164\n",
      "156: 0.17721406370401382\n",
      "157: 0.1262620110064745\n",
      "158: 0.13111085817217827\n",
      "159: 0.09809613972902298\n",
      "160: 0.1489892080426216\n",
      "161: 0.16485245525836945\n",
      "162: 0.13241082429885864\n",
      "163: 0.1288337204605341\n",
      "164: 0.11481902003288269\n",
      "165: 0.1316480189561844\n",
      "166: 0.16112477704882622\n",
      "167: 0.15765531547367573\n",
      "168: 0.15027138218283653\n",
      "169: 0.11358692497015\n",
      "170: 0.09527058061212301\n",
      "171: 0.13639496453106403\n",
      "172: 0.08163456246256828\n",
      "173: 0.15471321158111095\n",
      "174: 0.11508776340633631\n",
      "175: 0.1095130406320095\n",
      "176: 0.10478275548666716\n",
      "177: 0.09650281071662903\n",
      "178: 0.11905799433588982\n",
      "179: 0.10059105232357979\n",
      "180: 0.11503703985363245\n",
      "181: 0.12243260443210602\n",
      "182: 0.11333959922194481\n",
      "183: 0.1774223856627941\n",
      "184: 0.10621866025030613\n",
      "185: 0.10642019286751747\n",
      "186: 0.1324199065566063\n",
      "187: 0.12584601156413555\n",
      "188: 0.1293067578226328\n",
      "189: 0.10613454878330231\n",
      "190: 0.11704085301607847\n",
      "191: 0.11083458177745342\n",
      "192: 0.12923734355717897\n",
      "193: 0.14633319340646267\n",
      "194: 0.1398756094276905\n",
      "195: 0.10732386726886034\n",
      "196: 0.11320033390074968\n",
      "197: 0.14506108313798904\n",
      "198: 0.13902533426880836\n",
      "199: 0.12048223800957203\n",
      "200: 0.10868496727198362\n",
      "201: 0.13379612565040588\n",
      "202: 0.12306129839271307\n",
      "203: 0.1320606879889965\n",
      "204: 0.13900562841445208\n",
      "205: 0.1402793973684311\n",
      "206: 0.09398836456239223\n",
      "207: 0.15172018855810165\n",
      "208: 0.13078268617391586\n",
      "209: 0.10147340968251228\n",
      "210: 0.10742399375885725\n",
      "211: 0.09890371654182673\n",
      "212: 0.10414525121450424\n",
      "213: 0.11703073233366013\n",
      "214: 0.12245400063693523\n",
      "215: 0.13471311517059803\n",
      "216: 0.1661847159266472\n",
      "217: 0.13493420742452145\n",
      "218: 0.11679904721677303\n",
      "219: 0.13570957258343697\n",
      "220: 0.11834059283137321\n",
      "221: 0.10925336368381977\n",
      "222: 0.14690666645765305\n",
      "223: 0.1252391617745161\n",
      "224: 0.17614779621362686\n",
      "225: 0.14194372296333313\n",
      "226: 0.09150768537074327\n",
      "227: 0.12908962555229664\n",
      "228: 0.10258958116173744\n",
      "229: 0.15010772831737995\n",
      "230: 0.13345761224627495\n",
      "231: 0.1485971538349986\n",
      "232: 0.09958869498223066\n",
      "233: 0.12963702250272036\n",
      "234: 0.15129123255610466\n",
      "235: 0.09319810941815376\n",
      "236: 0.12224162183701992\n",
      "237: 0.12169171683490276\n",
      "238: 0.11666533537209034\n",
      "239: 0.13818915747106075\n",
      "240: 0.12742876075208187\n",
      "241: 0.11365824192762375\n",
      "242: 0.12033805437386036\n",
      "243: 0.14660749211907387\n",
      "244: 0.11783544905483723\n",
      "245: 0.11484399065375328\n",
      "246: 0.11848349310457706\n",
      "247: 0.14115192368626595\n",
      "248: 0.12466902192682028\n",
      "249: 0.10337238106876612\n",
      "250: 0.13050267100334167\n",
      "251: 0.14777572080492973\n",
      "252: 0.15600721910595894\n",
      "253: 0.14852134697139263\n",
      "254: 0.13182558119297028\n",
      "255: 0.15382788702845573\n",
      "256: 0.1292124018073082\n",
      "257: 0.12270572409033775\n",
      "258: 0.13467023149132729\n",
      "259: 0.09128365200012922\n",
      "260: 0.09364950098097324\n",
      "261: 0.09714729525148869\n",
      "262: 0.12530939280986786\n",
      "263: 0.10007154103368521\n",
      "264: 0.142070684581995\n",
      "265: 0.16268147341907024\n",
      "266: 0.14710825867950916\n",
      "267: 0.11183194257318974\n",
      "268: 0.11739247106015682\n",
      "269: 0.11074752174317837\n",
      "270: 0.12399137206375599\n",
      "271: 0.13561202585697174\n",
      "272: 0.1515488661825657\n",
      "273: 0.1466483362019062\n",
      "274: 0.11547294817864895\n",
      "275: 0.10543363355100155\n",
      "276: 0.1288494812324643\n",
      "277: 0.12067714147269726\n",
      "278: 0.11342660523951054\n",
      "279: 0.13875706866383553\n",
      "280: 0.10288995131850243\n",
      "281: 0.1067472118884325\n",
      "282: 0.12932887487113476\n",
      "283: 0.11151203885674477\n",
      "284: 0.08483008202165365\n",
      "285: 0.1284985113888979\n",
      "286: 0.10078173223882914\n",
      "287: 0.09509783796966076\n",
      "288: 0.11227918602526188\n",
      "289: 0.11861611343920231\n",
      "290: 0.10070248879492283\n",
      "291: 0.14992990251630545\n",
      "292: 0.13310055062174797\n",
      "293: 0.1374548263847828\n",
      "294: 0.15033289976418018\n",
      "295: 0.1268597487360239\n",
      "296: 0.13252952322363853\n",
      "297: 0.11528073251247406\n",
      "298: 0.12102396227419376\n",
      "299: 0.11273716576397419\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n",
    "        inputs_gauss = gauss_vicinal(inputs, gauss_vicinal_std)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_gauss)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('{}: {}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brief-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './gauss_model_pytorch_breast')\n",
    "model = fc_model()\n",
    "model.load_state_dict(torch.load('./gauss_model_pytorch_breast'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "latin-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        predicts = (torch.sign(outputs) + 1) / 2\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "resident-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970674486803519\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.type(torch.FloatTensor).reshape(-1, 1).to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        predicts = (torch.sign(outputs) + 1) / 2\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-galaxy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
